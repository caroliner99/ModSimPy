{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Simulation in Python\n",
    "\n",
    "Chapter 4\n",
    "\n",
    "Copyright 2017 Allen Downey\n",
    "\n",
    "License: [Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Jupyter so figures appear in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Configure Jupyter to display the assigned value after an assignment\n",
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'\n",
    "\n",
    "# import functions from the modsim library\n",
    "from modsim import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple function that returns a value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_five(x):\n",
    "    return x + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's how we call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = add_five(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run a function on the last line of a cell, Jupyter displays the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_five(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that can be a bad habit, because usually if you call a function and don't assign the result in a variable, the result gets discarded.\n",
    "\n",
    "In the following example, Jupyter shows the second result, but the first result just disappears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_five(3)\n",
    "add_five(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you call a function that returns a variable, it is generally a good idea to assign the result to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 10\n"
     ]
    }
   ],
   "source": [
    "y1 = add_five(3)\n",
    "y2 = add_five(5)\n",
    "\n",
    "print(y1, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Write a function called `make_state` that creates a `State` object with the state variables `olin=10` and `wellesley=2`, and then returns the new `State` object.\n",
    "\n",
    "Write a line of code that calls `make_state` and assigns the result to a variable named `init`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_state():\n",
    "    init = State(olin=10,wellesley=2)\n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2\n"
     ]
    }
   ],
   "source": [
    "init = make_state()\n",
    "print(init.olin,init.wellesley)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the code from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(state, p1, p2):\n",
    "    \"\"\"Simulate one minute of time.\n",
    "    \n",
    "    state: bikeshare State object\n",
    "    p1: probability of an Olin->Wellesley customer arrival\n",
    "    p2: probability of a Wellesley->Olin customer arrival\n",
    "    \"\"\"\n",
    "    if flip(p1):\n",
    "        bike_to_wellesley(state)\n",
    "    \n",
    "    if flip(p2):\n",
    "        bike_to_olin(state)\n",
    "        \n",
    "def bike_to_wellesley(state):\n",
    "    \"\"\"Move one bike from Olin to Wellesley.\n",
    "    \n",
    "    state: bikeshare State object\n",
    "    \"\"\"\n",
    "    if state.olin == 0:\n",
    "        state.olin_empty += 1\n",
    "        return\n",
    "    state.olin -= 1\n",
    "    state.wellesley += 1\n",
    "    \n",
    "def bike_to_olin(state):\n",
    "    \"\"\"Move one bike from Wellesley to Olin.\n",
    "    \n",
    "    state: bikeshare State object\n",
    "    \"\"\"\n",
    "    if state.wellesley == 0:\n",
    "        state.wellesley_empty += 1\n",
    "        return\n",
    "    state.wellesley -= 1\n",
    "    state.olin += 1\n",
    "    \n",
    "def decorate_bikeshare():\n",
    "    \"\"\"Add a title and label the axes.\"\"\"\n",
    "    decorate(title='Olin-Wellesley Bikeshare',\n",
    "             xlabel='Time step (min)', \n",
    "             ylabel='Number of bikes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a modified version of `run_simulation` that creates a `State` object, runs the simulation, and returns the `State` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(p1, p2, num_steps):\n",
    "    \"\"\"Simulate the given number of time steps.\n",
    "    \n",
    "    p1: probability of an Olin->Wellesley customer arrival\n",
    "    p2: probability of a Wellesley->Olin customer arrival\n",
    "    num_steps: number of time steps\n",
    "    \"\"\"\n",
    "    state = State(olin=10, wellesley=2, \n",
    "                  olin_empty=0, wellesley_empty=0)\n",
    "                    \n",
    "    for i in range(num_steps):\n",
    "        step(state, p1, p2)\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `run_simulation` doesn't plot anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>olin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wellesley</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olin_empty</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wellesley_empty</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "olin                0\n",
       "wellesley          12\n",
       "olin_empty          0\n",
       "wellesley_empty     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = run_simulation(0.4, 0.2, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But after the simulation, we can read the metrics from the `State` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.olin_empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run simulations with different values for the parameters.  When `p1` is small, we probably don't run out of bikes at Olin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = run_simulation(0.2, 0.2, 60)\n",
    "state.olin_empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `p1` is large, we probably do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = run_simulation(0.6, 0.2, 60)\n",
    "state.olin_empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More for loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`linspace` creates a NumPy array of equally spaced numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.25, 0.5 , 0.75, 1.  ])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1_array = linspace(0, 1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use an array in a `for` loop, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.25\n",
      "0.5\n",
      "0.75\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for p1 in p1_array:\n",
    "    print(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will come in handy in the next section.\n",
    "\n",
    "`linspace` is defined in `modsim.py`.  You can get the documentation using `help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function linspace in module modsim:\n",
      "\n",
      "linspace(start, stop, num=50, **options)\n",
      "    Returns an array of evenly-spaced values in the interval [start, stop].\n",
      "    \n",
      "    start: first value\n",
      "    stop: last value\n",
      "    num: number of values\n",
      "    \n",
      "    Also accepts the same keyword arguments as np.linspace.  See\n",
      "    https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html\n",
      "    \n",
      "    returns: array or Quantity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(linspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`linspace` is based on a NumPy function with the same name.  [Click here](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html) to read more about how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "Use `linspace` to make an array of 10 equally spaced numbers from 1 to 10 (including both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linspace(1,10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** The `modsim` library provides a related function called `linrange`.  You can view the documentation by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function linrange in module modsim:\n",
      "\n",
      "linrange(start=0, stop=None, step=1, **options)\n",
      "    Returns an array of evenly-spaced values in the interval [start, stop].\n",
      "    \n",
      "    This function works best if the space between start and stop\n",
      "    is divisible by step; otherwise the results might be surprising.\n",
      "    \n",
      "    By default, the last value in the array is `stop-step`\n",
      "    (at least approximately).\n",
      "    If you provide the keyword argument `endpoint=True`,\n",
      "    the last value in the array is `stop`.\n",
      "    \n",
      "    start: first value\n",
      "    stop: last value\n",
      "    step: space between values\n",
      "    \n",
      "    Also accepts the same keyword arguments as np.linspace.  See\n",
      "    https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html\n",
      "    \n",
      "    returns: array or Quantity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(linrange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `linrange` to make an array of numbers from 1 to 11 with a step size of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  3.,  5.,  7.,  9., 11.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linrange(1,13,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweeping parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`p1_array` contains a range of values for `p1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = 0.2\n",
    "num_steps = 60\n",
    "p1_array = linspace(0, 1, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loop runs a simulation for each value of `p1` in `p1_array`; after each simulation, it prints the number of unhappy customers at the Olin station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0\n",
      "0.1 0\n",
      "0.2 0\n",
      "0.30000000000000004 0\n",
      "0.4 5\n",
      "0.5 14\n",
      "0.6000000000000001 12\n",
      "0.7000000000000001 9\n",
      "0.8 28\n",
      "0.9 33\n",
      "1.0 33\n"
     ]
    }
   ],
   "source": [
    "for p1 in p1_array:\n",
    "    state = run_simulation(p1, p2, num_steps)\n",
    "    print(p1, state.olin_empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do the same thing, but storing the results in a `SweepSeries` instead of printing them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep = SweepSeries()\n",
    "\n",
    "for p1 in p1_array:\n",
    "    state = run_simulation(p1, p2, num_steps)\n",
    "    sweep[p1] = state.olin_empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure to file figs/chap02-fig02.pdf\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(sweep, label='Olin')\n",
    "\n",
    "decorate(title='Olin-Wellesley Bikeshare',\n",
    "         xlabel='Arrival rate at Olin (p1 in customers/min)', \n",
    "         ylabel='Number of unhappy customers')\n",
    "\n",
    "savefig('figs/chap02-fig02.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "**Exercise:** Wrap this code in a function named `sweep_p1` that takes an array called `p1_array` as a parameter.  It should create a new `SweepSeries`, run a simulation for each value of `p1` in `p1_array`, store the results in the `SweepSeries`, and return the `SweepSeries`.\n",
    "\n",
    "Use your function to plot the number of unhappy customers at Olin as a function of `p1`.  Label the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_p1(p1_array):\n",
    "    sweep=SweepSeries()\n",
    "    for p1 in p1_array:\n",
    "        state = run_simulation(p1, p2, num_steps)\n",
    "        sweep[p1] = state.olin_empty\n",
    "    return sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot (sweep_p1(p1_array))\n",
    "decorate(title='Olin-Wellesley Bikeshare',\n",
    "         xlabel='Arrival rate at Olin (p1 in customers/min)', \n",
    "         ylabel='Number of unhappy customers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Write a function called `sweep_p2` that runs simulations with `p1=0.5` and a range of values for `p2`.  It should store the results in a `SweepSeries` and return the `SweepSeries`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_p2(p2_array):\n",
    "    sweep=SweepSeries()\n",
    "    for p2 in p2_array:\n",
    "        state = run_simulation(.5, p2, num_steps)\n",
    "        sweep[p2] = state.olin_empty\n",
    "    return sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p2_array = linrange(0,11,2)\n",
    "plot (sweep_p2(p2_array))\n",
    "decorate(title='Olin-Wellesley Bikeshare',\n",
    "         xlabel='Arrival rate at Wellesley (p2 in customers/min)', \n",
    "         ylabel='Number of unhappy customers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional exercises\n",
    "\n",
    "The following two exercises are a little more challenging.  If you are comfortable with what you have learned so far, you should give them a try.  If you feel like you have your hands full, you might want to skip them for now.\n",
    "\n",
    "**Exercise:** Because our simulations are random, the results vary from one run to another, and the results of a parameter sweep tend to be noisy.  We can get a clearer picture of the relationship between a parameter and a metric by running multiple simulations with the same parameter and taking the average of the results.\n",
    "\n",
    "Write a function called `run_multiple_simulations` that takes as parameters `p1`, `p2`, `num_steps`, and `num_runs`.\n",
    "\n",
    "`num_runs` specifies how many times it should call `run_simulation`.\n",
    "\n",
    "After each run, it should store the total number of unhappy customers (at Olin or Wellesley) in a `TimeSeries`.  At the end, it should return the `TimeSeries`.\n",
    "\n",
    "Test your function with parameters\n",
    "\n",
    "```\n",
    "p1 = 0.3\n",
    "p2 = 0.3\n",
    "num_steps = 60\n",
    "num_runs = 10\n",
    "```\n",
    "\n",
    "Display the resulting `TimeSeries` and use the `mean` function provided by the `TimeSeries` object to compute the average number of unhappy customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SweepSeries in module modsim:\n",
      "\n",
      "class SweepSeries(ModSimSeries)\n",
      " |  Represents a mapping from parameter values to metrics.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SweepSeries\n",
      " |      ModSimSeries\n",
      " |      pandas.core.series.Series\n",
      " |      pandas.core.base.IndexOpsMixin\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from ModSimSeries:\n",
      " |  \n",
      " |  __copy__(self, deep=True)\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initialize a Series.\n",
      " |      \n",
      " |      Note: this cleans up a weird Series behavior, which is\n",
      " |      that Series() and Series([]) yield different results.\n",
      " |      See: https://github.com/pandas-dev/pandas/issues/16737\n",
      " |  \n",
      " |  copy = __copy__(self, deep=True)\n",
      " |  \n",
      " |  set(self, **kwargs)\n",
      " |      Uses keyword arguments to update the Series in place.\n",
      " |      \n",
      " |      Example: series.set(a=1, b=2)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from ModSimSeries:\n",
      " |  \n",
      " |  T\n",
      " |      Intercept the Series accessor object so we can use `T`\n",
      " |      as a row label and access it using dot notation.\n",
      " |      \n",
      " |      https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.T.html\n",
      " |  \n",
      " |  dt\n",
      " |      Intercept the Series accessor object so we can use `dt`\n",
      " |      as a row label and access it using dot notation.\n",
      " |      \n",
      " |      https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.dt.html\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.series.Series:\n",
      " |  \n",
      " |  __add__ = wrapper(left, right)\n",
      " |  \n",
      " |  __and__ = wrapper(self, other)\n",
      " |  \n",
      " |  __array__(self, result=None)\n",
      " |      the array interface, return my values\n",
      " |  \n",
      " |  __array_prepare__(self, result, context=None)\n",
      " |      Gets called prior to a ufunc\n",
      " |  \n",
      " |  __array_wrap__(self, result, context=None)\n",
      " |      Gets called after a ufunc\n",
      " |  \n",
      " |  __div__ = wrapper(left, right)\n",
      " |  \n",
      " |  __divmod__ = wrapper(left, right)\n",
      " |  \n",
      " |  __eq__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __float__ = wrapper(self)\n",
      " |  \n",
      " |  __floordiv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __ge__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __gt__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __iadd__ = f(self, other)\n",
      " |  \n",
      " |  __iand__ = f(self, other)\n",
      " |  \n",
      " |  __ifloordiv__ = f(self, other)\n",
      " |  \n",
      " |  __imod__ = f(self, other)\n",
      " |  \n",
      " |  __imul__ = f(self, other)\n",
      " |  \n",
      " |  __int__ = wrapper(self)\n",
      " |  \n",
      " |  __ior__ = f(self, other)\n",
      " |  \n",
      " |  __ipow__ = f(self, other)\n",
      " |  \n",
      " |  __isub__ = f(self, other)\n",
      " |  \n",
      " |  __itruediv__ = f(self, other)\n",
      " |  \n",
      " |  __ixor__ = f(self, other)\n",
      " |  \n",
      " |  __le__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      return the length of the Series\n",
      " |  \n",
      " |  __long__ = wrapper(self)\n",
      " |  \n",
      " |  __lt__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __matmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5\n",
      " |  \n",
      " |  __mod__ = wrapper(left, right)\n",
      " |  \n",
      " |  __mul__ = wrapper(left, right)\n",
      " |  \n",
      " |  __ne__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __or__ = wrapper(self, other)\n",
      " |  \n",
      " |  __pow__ = wrapper(left, right)\n",
      " |  \n",
      " |  __radd__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rand__ = wrapper(self, other)\n",
      " |  \n",
      " |  __rdiv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rfloordiv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5\n",
      " |  \n",
      " |  __rmod__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rmul__ = wrapper(left, right)\n",
      " |  \n",
      " |  __ror__ = wrapper(self, other)\n",
      " |  \n",
      " |  __rpow__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rsub__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rtruediv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rxor__ = wrapper(self, other)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  __sub__ = wrapper(left, right)\n",
      " |  \n",
      " |  __truediv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular DataFrame\n",
      " |      \n",
      " |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  __xor__ = wrapper(self, other)\n",
      " |  \n",
      " |  add(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Addition of series and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``series + other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.radd\n",
      " |  \n",
      " |  agg = aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, string, dictionary, or list of string/functions\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply. For\n",
      " |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - string function name.\n",
      " |          - function.\n",
      " |          - list of functions.\n",
      " |          - dict of column names -> functions (or list of functions).\n",
      " |      \n",
      " |      \n",
      " |      axis : {0 or 'index'}\n",
      " |          Parameter needed for compatibility with DataFrame.\n",
      " |      \n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aggregated : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = Series(np.random.randn(10))\n",
      " |      \n",
      " |      >>> s.agg('min')\n",
      " |      -1.3018049988556679\n",
      " |      \n",
      " |      >>> s.agg(['min', 'max'])\n",
      " |      min   -1.301805\n",
      " |      max    1.127688\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.apply\n",
      " |      pandas.Series.transform\n",
      " |  \n",
      " |  aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, string, dictionary, or list of string/functions\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply. For\n",
      " |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - string function name.\n",
      " |          - function.\n",
      " |          - list of functions.\n",
      " |          - dict of column names -> functions (or list of functions).\n",
      " |      \n",
      " |      \n",
      " |      axis : {0 or 'index'}\n",
      " |          Parameter needed for compatibility with DataFrame.\n",
      " |      \n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aggregated : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = Series(np.random.randn(10))\n",
      " |      \n",
      " |      >>> s.agg('min')\n",
      " |      -1.3018049988556679\n",
      " |      \n",
      " |      >>> s.agg(['min', 'max'])\n",
      " |      min   -1.301805\n",
      " |      max    1.127688\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.apply\n",
      " |      pandas.Series.transform\n",
      " |  \n",
      " |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      " |      Align two objects on their axes with the\n",
      " |      specified join method for each axis Index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None)\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      copy : boolean, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      method : str, default None\n",
      " |      limit : int, default None\n",
      " |      fill_axis : {0 or 'index'}, default 0\n",
      " |          Filling axis, method and limit\n",
      " |      broadcast_axis : {0 or 'index'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (Series, type of other)\n",
      " |          Aligned objects\n",
      " |  \n",
      " |  all(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |      \n",
      " |      Returns True if all elements within a series or along a Dataframe\n",
      " |      axis are non-zero, not-empty or not-False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      all : scalar or Series (if level specified)\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.all : Return True if all elements are True\n",
      " |      pandas.DataFrame.any : Return True if one (or more) elements are True\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Series\n",
      " |      \n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      \n",
      " |      DataFrames\n",
      " |      \n",
      " |      Create a dataframe from a dictionary.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |      \n",
      " |      Default behaviour checks if column-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Specify ``axis='columns'`` to check if row-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |      \n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |  \n",
      " |  any(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether any element is True over requested axis.\n",
      " |      \n",
      " |      Unlike :meth:`DataFrame.all`, this performs an *or* operation. If any of the\n",
      " |      values along the specified axis is True, this will return True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      any : scalar or Series (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.all : Return whether all elements are True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |      \n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |      \n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |      \n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |      \n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |      \n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |  \n",
      " |  append(self, to_append, ignore_index=False, verify_integrity=False)\n",
      " |      Concatenate two or more Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_append : Series or list/tuple of Series\n",
      " |      ignore_index : boolean, default False\n",
      " |          If True, do not use the index labels.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      verify_integrity : boolean, default False\n",
      " |          If True, raise Exception on creating index with duplicates\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Iteratively appending to a Series can be more computationally intensive\n",
      " |      than a single concatenate. A better solution is to append values to a\n",
      " |      list and then concatenate the list with the original Series all at\n",
      " |      once.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.concat : General function to concatenate DataFrame, Series\n",
      " |          or Panel objects\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      appended : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([1, 2, 3])\n",
      " |      >>> s2 = pd.Series([4, 5, 6])\n",
      " |      >>> s3 = pd.Series([4, 5, 6], index=[3,4,5])\n",
      " |      >>> s1.append(s2)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s1.append(s3)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, ignore_index=True)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `verify_integrity` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, verify_integrity=True)\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: Indexes have overlapping values: [0, 1, 2]\n",
      " |  \n",
      " |  apply(self, func, convert_dtype=True, args=(), **kwds)\n",
      " |      Invoke function on values of Series. Can be ufunc (a NumPy function\n",
      " |      that applies to the entire Series) or a Python function that only works\n",
      " |      on single values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |      convert_dtype : boolean, default True\n",
      " |          Try to find better dtype for elementwise function results. If\n",
      " |          False, leave as dtype=object\n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to function in addition to the value\n",
      " |      Additional keyword arguments will be passed as keywords to the function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series or DataFrame if func returns a Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.map: For element-wise operations\n",
      " |      Series.agg: only perform aggregating type operations\n",
      " |      Series.transform: only perform transformating type operations\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create a series with typical summer temperatures for each city.\n",
      " |      \n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> series = pd.Series([20, 21, 12], index=['London',\n",
      " |      ... 'New York','Helsinki'])\n",
      " |      >>> series\n",
      " |      London      20\n",
      " |      New York    21\n",
      " |      Helsinki    12\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by defining a function and passing it as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> def square(x):\n",
      " |      ...     return x**2\n",
      " |      >>> series.apply(square)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by passing an anonymous function as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> series.apply(lambda x: x**2)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that needs additional positional\n",
      " |      arguments and pass these additional arguments using the\n",
      " |      ``args`` keyword.\n",
      " |      \n",
      " |      >>> def subtract_custom_value(x, custom_value):\n",
      " |      ...     return x-custom_value\n",
      " |      \n",
      " |      >>> series.apply(subtract_custom_value, args=(5,))\n",
      " |      London      15\n",
      " |      New York    16\n",
      " |      Helsinki     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that takes keyword arguments\n",
      " |      and pass these arguments to ``apply``.\n",
      " |      \n",
      " |      >>> def add_custom_values(x, **kwargs):\n",
      " |      ...     for month in kwargs:\n",
      " |      ...         x+=kwargs[month]\n",
      " |      ...     return x\n",
      " |      \n",
      " |      >>> series.apply(add_custom_values, june=30, july=20, august=25)\n",
      " |      London      95\n",
      " |      New York    96\n",
      " |      Helsinki    87\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a function from the Numpy library.\n",
      " |      \n",
      " |      >>> series.apply(np.log)\n",
      " |      London      2.995732\n",
      " |      New York    3.044522\n",
      " |      Helsinki    2.484907\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  argmax = idxmax(self, axis=0, skipna=True, *args, **kwargs)\n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |         'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      " |          will be corrected to return the positional maximum in the future. Use\n",
      " |          'series.values.argmax' to get the position of the maximum now.\n",
      " |      \n",
      " |      \n",
      " |      Return the row label of the maximum value.\n",
      " |      \n",
      " |      If multiple values equal the maximum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmax. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Index of maximum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``. This method\n",
      " |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      " |      the position. To get the position, use ``series.values.argmax()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmax : Return indices of the maximum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmax : Return index of first occurrence of maximum\n",
      " |          over requested axis.\n",
      " |      Series.idxmin : Return index *label* of the first occurrence\n",
      " |          of minimum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 3, 4],\n",
      " |      ...               index=['A', 'B', 'C', 'D', 'E'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    3.0\n",
      " |      E    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmax()\n",
      " |      'C'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmax(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  argmin = idxmin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |         'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      " |          will be corrected to return the positional minimum in the future. Use\n",
      " |          'series.values.argmin' to get the position of the minimum now.\n",
      " |      \n",
      " |      \n",
      " |      Return the row label of the minimum value.\n",
      " |      \n",
      " |      If multiple values equal the minimum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmin. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Index of minimum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``. This method\n",
      " |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      " |      the position. To get the position, use ``series.values.argmin()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmin : Return indices of the minimum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmin : Return index of first occurrence of minimum\n",
      " |          over requested axis.\n",
      " |      Series.idxmax : Return index *label* of the first occurrence\n",
      " |          of maximum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 1],\n",
      " |      ...               index=['A' ,'B' ,'C' ,'D'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmin()\n",
      " |      'A'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmin(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  argsort(self, axis=0, kind='quicksort', order=None)\n",
      " |      Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,\n",
      " |      and places the result in the same locations as the non-NA values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int (can only be zero)\n",
      " |      kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See np.sort for more\n",
      " |          information. 'mergesort' is the only stable algorithm\n",
      " |      order : ignored\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      argsorted : Series, with -1 indicated where nan values are present\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.argsort\n",
      " |  \n",
      " |  autocorr(self, lag=1)\n",
      " |      Lag-N autocorrelation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lag : int, default 1\n",
      " |          Number of lags to apply before performing autocorrelation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      autocorr : float\n",
      " |  \n",
      " |  between(self, left, right, inclusive=True)\n",
      " |      Return boolean Series equivalent to left <= series <= right.\n",
      " |      \n",
      " |      This function returns a boolean vector containing `True` wherever the\n",
      " |      corresponding Series element is between the boundary values `left` and\n",
      " |      `right`. NA values are treated as `False`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      left : scalar\n",
      " |          Left boundary.\n",
      " |      right : scalar\n",
      " |          Right boundary.\n",
      " |      inclusive : bool, default True\n",
      " |          Include boundaries.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Each element will be a boolean.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function is equivalent to ``(left <= ser) & (ser <= right)``\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.gt : Greater than of series and other\n",
      " |      pandas.Series.lt : Less than of series and other\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([2, 0, 4, 8, np.nan])\n",
      " |      \n",
      " |      Boundary values are included by default:\n",
      " |      \n",
      " |      >>> s.between(1, 4)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      With `inclusive` set to ``False`` boundary values are excluded:\n",
      " |      \n",
      " |      >>> s.between(1, 4, inclusive=False)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      `left` and `right` can be any scalar value:\n",
      " |      \n",
      " |      >>> s = pd.Series(['Alice', 'Bob', 'Carol', 'Eve'])\n",
      " |      >>> s.between('Anna', 'Daniel')\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  combine(self, other, func, fill_value=nan)\n",
      " |      Perform elementwise binary operation on two Series using given function\n",
      " |      with optional fill value when an index is missing from one Series or\n",
      " |      the other\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      func : function\n",
      " |          Function that takes two scalars as inputs and return a scalar\n",
      " |      fill_value : scalar value\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = Series([1, 2])\n",
      " |      >>> s2 = Series([0, 3])\n",
      " |      >>> s1.combine(s2, lambda x1, x2: x1 if x1 < x2 else x2)\n",
      " |      0    0\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.combine_first : Combine Series values, choosing the calling\n",
      " |          Series's values first\n",
      " |  \n",
      " |  combine_first(self, other)\n",
      " |      Combine Series values, choosing the calling Series's values\n",
      " |      first. Result index will be the union of the two indexes\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      combined : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([1, np.nan])\n",
      " |      >>> s2 = pd.Series([3, 4])\n",
      " |      >>> s1.combine_first(s2)\n",
      " |      0    1.0\n",
      " |      1    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.combine : Perform elementwise operation on two Series\n",
      " |          using a given function\n",
      " |  \n",
      " |  compound(self, axis=None, skipna=None, level=None)\n",
      " |      Return the compound percentage of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      compounded : scalar or Series (if level specified)\n",
      " |  \n",
      " |  compress(self, condition, *args, **kwargs)\n",
      " |      Return selected slices of an array along given axis as a Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.compress\n",
      " |  \n",
      " |  corr(self, other, method='pearson', min_periods=None)\n",
      " |      Compute correlation with `other` Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      method : {'pearson', 'kendall', 'spearman'}\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correlation : float\n",
      " |  \n",
      " |  count(self, level=None)\n",
      " |      Return number of non-NA/null observations in the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a smaller Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nobs : int or Series (if level specified)\n",
      " |  \n",
      " |  cov(self, other, min_periods=None)\n",
      " |      Compute covariance with Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      covariance : float\n",
      " |      \n",
      " |      Normalized by N-1 (unbiased estimator).\n",
      " |  \n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummax : scalar or Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.max : Return the maximum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |  \n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummin : scalar or Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.min : Return the minimum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |  \n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumprod : scalar or Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.prod : Return the product over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |  \n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumsum : scalar or Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.sum : Return the sum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |  \n",
      " |  diff(self, periods=1)\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a Series element compared with another\n",
      " |      element in the Series (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pct_change: Percent change over given number of periods.\n",
      " |      Series.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      DataFrame.diff: First discrete difference of object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 1, 2, 3, 5, 8])\n",
      " |      >>> s.diff()\n",
      " |      0    NaN\n",
      " |      1    0.0\n",
      " |      2    1.0\n",
      " |      3    1.0\n",
      " |      4    2.0\n",
      " |      5    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> s.diff(periods=3)\n",
      " |      0    NaN\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    2.0\n",
      " |      4    4.0\n",
      " |      5    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> s.diff(periods=-1)\n",
      " |      0    0.0\n",
      " |      1   -1.0\n",
      " |      2   -1.0\n",
      " |      3   -2.0\n",
      " |      4   -3.0\n",
      " |      5    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  div = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  divide = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  divmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division and modulo of series and other, element-wise (binary operator `divmod`).\n",
      " |      \n",
      " |      Equivalent to ``series divmod other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Matrix multiplication with DataFrame or inner-product with Series\n",
      " |      objects. Can also be called using `self @ other` in Python >= 3.5.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dot_product : scalar or Series\n",
      " |  \n",
      " |  drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
      " |      Return Series with specified index labels removed.\n",
      " |      \n",
      " |      Remove elements of a Series based on specifying the index labels.\n",
      " |      When using a multi-index, labels on different levels can be removed\n",
      " |      by specifying the level.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index labels to drop.\n",
      " |      axis : 0, default 0\n",
      " |          Redundant for application on Series.\n",
      " |      index, columns : None\n",
      " |          Redundant for application on Series, but index can be used instead\n",
      " |          of labels.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level for which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are dropped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dropped : pandas.Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.reindex : Return only specified index labels of Series.\n",
      " |      Series.dropna : Return series without null values.\n",
      " |      Series.drop_duplicates : Return Series with duplicate values removed.\n",
      " |      DataFrame.drop : Drop specified labels from rows or columns.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If none of the labels are found in the index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=np.arange(3), index=['A','B','C'])\n",
      " |      >>> s\n",
      " |      A  0\n",
      " |      B  1\n",
      " |      C  2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Drop labels B en C\n",
      " |      \n",
      " |      >>> s.drop(labels=['B','C'])\n",
      " |      A  0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Drop 2nd level label in MultiIndex Series\n",
      " |      \n",
      " |      >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      labels=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                              [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> s = pd.Series([45, 200, 1.2, 30, 250, 1.5, 320, 1, 0.3],\n",
      " |      ...               index=midx)\n",
      " |      >>> s\n",
      " |      lama    speed      45.0\n",
      " |              weight    200.0\n",
      " |              length      1.2\n",
      " |      cow     speed      30.0\n",
      " |              weight    250.0\n",
      " |              length      1.5\n",
      " |      falcon  speed     320.0\n",
      " |              weight      1.0\n",
      " |              length      0.3\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.drop(labels='weight', level=1)\n",
      " |      lama    speed      45.0\n",
      " |              length      1.2\n",
      " |      cow     speed      30.0\n",
      " |              length      1.5\n",
      " |      falcon  speed     320.0\n",
      " |              length      0.3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  drop_duplicates(self, keep='first', inplace=False)\n",
      " |      Return Series with duplicate values removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', ``False``}, default 'first'\n",
      " |          - 'first' : Drop duplicates except for the first occurrence.\n",
      " |          - 'last' : Drop duplicates except for the last occurrence.\n",
      " |          - ``False`` : Drop all duplicates.\n",
      " |      inplace : boolean, default ``False``\n",
      " |          If ``True``, performs operation inplace and returns None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      deduplicated : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.drop_duplicates : equivalent method on Index\n",
      " |      DataFrame.drop_duplicates : equivalent method on DataFrame\n",
      " |      Series.duplicated : related method on Series, indicating duplicate\n",
      " |          Series values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Generate an Series with duplicated entries.\n",
      " |      \n",
      " |      >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama', 'hippo'],\n",
      " |      ...               name='animal')\n",
      " |      >>> s\n",
      " |      0      lama\n",
      " |      1       cow\n",
      " |      2      lama\n",
      " |      3    beetle\n",
      " |      4      lama\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      With the 'keep' parameter, the selection behaviour of duplicated values\n",
      " |      can be changed. The value 'first' keeps the first occurrence for each\n",
      " |      set of duplicated entries. The default value of keep is 'first'.\n",
      " |      \n",
      " |      >>> s.drop_duplicates()\n",
      " |      0      lama\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      The value 'last' for parameter 'keep' keeps the last occurrence for\n",
      " |      each set of duplicated entries.\n",
      " |      \n",
      " |      >>> s.drop_duplicates(keep='last')\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      4      lama\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      The value ``False`` for parameter 'keep' discards all sets of\n",
      " |      duplicated entries. Setting the value of 'inplace' to ``True`` performs\n",
      " |      the operation inplace and returns ``None``.\n",
      " |      \n",
      " |      >>> s.drop_duplicates(keep=False, inplace=True)\n",
      " |      >>> s\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |  \n",
      " |  dropna(self, axis=0, inplace=False, **kwargs)\n",
      " |      Return a new Series with missing values removed.\n",
      " |      \n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}, default 0\n",
      " |          There is only one axis to drop values from.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      **kwargs\n",
      " |          Not in use.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series with NA entries dropped from it.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isna: Indicate missing values.\n",
      " |      Series.notna : Indicate existing (non-missing) values.\n",
      " |      Series.fillna : Replace missing values.\n",
      " |      DataFrame.dropna : Drop rows or columns which contain NA values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1., 2., np.nan])\n",
      " |      >>> ser\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Drop NA values from a Series.\n",
      " |      \n",
      " |      >>> ser.dropna()\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Keep the Series with valid entries in the same variable.\n",
      " |      \n",
      " |      >>> ser.dropna(inplace=True)\n",
      " |      >>> ser\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Empty strings are not considered NA values. ``None`` is considered an\n",
      " |      NA value.\n",
      " |      \n",
      " |      >>> ser = pd.Series([np.NaN, 2, pd.NaT, '', None, 'I stay'])\n",
      " |      >>> ser\n",
      " |      0       NaN\n",
      " |      1         2\n",
      " |      2       NaT\n",
      " |      3\n",
      " |      4      None\n",
      " |      5    I stay\n",
      " |      dtype: object\n",
      " |      >>> ser.dropna()\n",
      " |      1         2\n",
      " |      3\n",
      " |      5    I stay\n",
      " |      dtype: object\n",
      " |  \n",
      " |  duplicated(self, keep='first')\n",
      " |      Indicate duplicate Series values.\n",
      " |      \n",
      " |      Duplicated values are indicated as ``True`` values in the resulting\n",
      " |      Series. Either all duplicates, all except the first or all except the\n",
      " |      last occurrence of duplicates can be indicated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - 'first' : Mark duplicates as ``True`` except for the first\n",
      " |            occurrence.\n",
      " |          - 'last' : Mark duplicates as ``True`` except for the last\n",
      " |            occurrence.\n",
      " |          - ``False`` : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, for each set of duplicated values, the first occurrence is\n",
      " |      set on False and all others on True:\n",
      " |      \n",
      " |      >>> animals = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama'])\n",
      " |      >>> animals.duplicated()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      which is equivalent to\n",
      " |      \n",
      " |      >>> animals.duplicated(keep='first')\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By using 'last', the last occurrence of each set of duplicated values\n",
      " |      is set on False and all others on True:\n",
      " |      \n",
      " |      >>> animals.duplicated(keep='last')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By setting keep on ``False``, all duplicates are True:\n",
      " |      \n",
      " |      >>> animals.duplicated(keep=False)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.core.series.Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Index.duplicated : Equivalent method on pandas.Index\n",
      " |      pandas.DataFrame.duplicated : Equivalent method on pandas.DataFrame\n",
      " |      pandas.Series.drop_duplicates : Remove duplicate values from Series\n",
      " |  \n",
      " |  eq(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Equal to of series and other, element-wise (binary operator `eq`).\n",
      " |      \n",
      " |      Equivalent to ``series == other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=0)\n",
      " |      Provides exponential weighted functions\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass,\n",
      " |          :math:`\\alpha = 1 / (1 + com),\\text{ for } com \\geq 0`\n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span,\n",
      " |          :math:`\\alpha = 2 / (span + 1),\\text{ for } span \\geq 1`\n",
      " |      halflife : float, optional\n",
      " |          Specify decay in terms of half-life,\n",
      " |          :math:`\\alpha = 1 - exp(log(0.5) / halflife),\\text{ for } halflife > 0`\n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly,\n",
      " |          :math:`0 < \\alpha \\leq 1`\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      adjust : boolean, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average)\n",
      " |      ignore_na : boolean, default False\n",
      " |          Ignore missing values when calculating weights;\n",
      " |          specify True to reproduce pre-0.15.0 behavior\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Exactly one of center of mass, span, half-life, and alpha must be provided.\n",
      " |      Allowed values and relationship between the parameters are specified in the\n",
      " |      parameter descriptions above; see the link at the end of this section for\n",
      " |      a detailed explanation.\n",
      " |      \n",
      " |      When adjust is True (default), weighted averages are calculated using\n",
      " |      weights (1-alpha)**(n-1), (1-alpha)**(n-2), ..., 1-alpha, 1.\n",
      " |      \n",
      " |      When adjust is False, weighted averages are calculated recursively as:\n",
      " |         weighted_average[0] = arg[0];\n",
      " |         weighted_average[i] = (1-alpha)*weighted_average[i-1] + alpha*arg[i].\n",
      " |      \n",
      " |      When ignore_na is False (default), weights are based on absolute positions.\n",
      " |      For example, the weights of x and y used in calculating the final weighted\n",
      " |      average of [x, None, y] are (1-alpha)**2 and 1 (if adjust is True), and\n",
      " |      (1-alpha)**2 and alpha (if adjust is False).\n",
      " |      \n",
      " |      When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based\n",
      " |      on relative positions. For example, the weights of x and y used in\n",
      " |      calculating the final weighted average of [x, None, y] are 1-alpha and 1\n",
      " |      (if adjust is True), and 1-alpha and alpha (if adjust is False).\n",
      " |      \n",
      " |      More details can be found at\n",
      " |      http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations\n",
      " |      expanding : Provides expanding transformations.\n",
      " |  \n",
      " |  expanding(self, min_periods=1, center=False, axis=0)\n",
      " |      Provides expanding transformations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.expanding(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations\n",
      " |      ewm : Provides exponential weighted functions\n",
      " |  \n",
      " |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
      " |      Fill NA/NaN values using the specified method\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame). (values not\n",
      " |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0 or 'index'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                    columns=list('ABCD'))\n",
      " |      >>> df\n",
      " |           A    B   C  D\n",
      " |      0  NaN  2.0 NaN  0\n",
      " |      1  3.0  4.0 NaN  1\n",
      " |      2  NaN  NaN NaN  5\n",
      " |      3  NaN  3.0 NaN  4\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method='ffill')\n",
      " |          A   B   C   D\n",
      " |      0   NaN 2.0 NaN 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   3.0 4.0 NaN 5\n",
      " |      3   3.0 3.0 NaN 4\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 2.0 1\n",
      " |      2   0.0 1.0 2.0 5\n",
      " |      3   0.0 3.0 2.0 4\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   NaN 1.0 NaN 5\n",
      " |      3   NaN 3.0 NaN 4\n",
      " |  \n",
      " |  floordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division of series and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``series // other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rfloordiv\n",
      " |  \n",
      " |  ge(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Greater than or equal to of series and other, element-wise (binary operator `ge`).\n",
      " |      \n",
      " |      Equivalent to ``series >= other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  get_value(self, label, takeable=False)\n",
      " |      Quickly retrieve single value at passed index label\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Please use .at[] or .iat[] accessors.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |      takeable : interpret the index as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : scalar value\n",
      " |  \n",
      " |  get_values(self)\n",
      " |      same as values (but handles sparseness conversions); is a view\n",
      " |  \n",
      " |  gt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Greater than of series and other, element-wise (binary operator `gt`).\n",
      " |      \n",
      " |      Equivalent to ``series > other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  hist = hist_series(self, by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, figsize=None, bins=10, **kwds)\n",
      " |      Draw histogram of the input series using matplotlib\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups\n",
      " |      ax : matplotlib axis object\n",
      " |          If not passed, uses gca()\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size\n",
      " |      xrot : float, default None\n",
      " |          rotation of x axis labels\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size\n",
      " |      yrot : float, default None\n",
      " |          rotation of y axis labels\n",
      " |      figsize : tuple, default None\n",
      " |          figure size in inches by default\n",
      " |      bins : integer or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      bins: integer, default 10\n",
      " |          Number of histogram bins to be used\n",
      " |      `**kwds` : keywords\n",
      " |          To be passed to the actual plotting function\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.axes.Axes.hist : Plot a histogram using matplotlib.\n",
      " |  \n",
      " |  idxmax(self, axis=0, skipna=True, *args, **kwargs)\n",
      " |      Return the row label of the maximum value.\n",
      " |      \n",
      " |      If multiple values equal the maximum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmax. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Index of maximum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``. This method\n",
      " |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      " |      the position. To get the position, use ``series.values.argmax()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmax : Return indices of the maximum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmax : Return index of first occurrence of maximum\n",
      " |          over requested axis.\n",
      " |      Series.idxmin : Return index *label* of the first occurrence\n",
      " |          of minimum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 3, 4],\n",
      " |      ...               index=['A', 'B', 'C', 'D', 'E'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    3.0\n",
      " |      E    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmax()\n",
      " |      'C'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmax(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  idxmin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return the row label of the minimum value.\n",
      " |      \n",
      " |      If multiple values equal the minimum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmin. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Index of minimum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``. This method\n",
      " |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      " |      the position. To get the position, use ``series.values.argmin()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmin : Return indices of the minimum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmin : Return index of first occurrence of minimum\n",
      " |          over requested axis.\n",
      " |      Series.idxmax : Return index *label* of the first occurrence\n",
      " |          of maximum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 1],\n",
      " |      ...               index=['A' ,'B' ,'C' ,'D'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmin()\n",
      " |      'A'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmin(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  isin(self, values)\n",
      " |      Check whether `values` are contained in Series.\n",
      " |      \n",
      " |      Return a boolean Series showing whether each element in the Series\n",
      " |      matches an element in the passed sequence of `values` exactly.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : set or list-like\n",
      " |          The sequence of values to test. Passing in a single string will\n",
      " |          raise a ``TypeError``. Instead, turn a single string into a\n",
      " |          list of one element.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |      \n",
      " |            Support for values as a set.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      isin : Series (bool dtype)\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |        * If `values` is a string\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.isin : equivalent method on DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama',\n",
      " |      ...                'hippo'], name='animal')\n",
      " |      >>> s.isin(['cow', 'lama'])\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      5    False\n",
      " |      Name: animal, dtype: bool\n",
      " |      \n",
      " |      Passing a single string as ``s.isin('lama')`` will raise an error. Use\n",
      " |      a list of one element instead:\n",
      " |      \n",
      " |      >>> s.isin(['lama'])\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      5    False\n",
      " |      Name: animal, dtype: bool\n",
      " |  \n",
      " |  isna(self)\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isnull : alias of isna\n",
      " |      Series.notna : boolean inverse of isna\n",
      " |      Series.dropna : omit axes labels with missing values\n",
      " |      isna : top-level isna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  isnull(self)\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isnull : alias of isna\n",
      " |      Series.notna : boolean inverse of isna\n",
      " |      Series.dropna : omit axes labels with missing values\n",
      " |      isna : top-level isna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items = iteritems(self)\n",
      " |      Lazily iterate over (index, value) tuples\n",
      " |  \n",
      " |  iteritems(self)\n",
      " |      Lazily iterate over (index, value) tuples\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Alias for index\n",
      " |  \n",
      " |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      kurt : scalar or Series (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      kurt : scalar or Series (if level specified)\n",
      " |  \n",
      " |  le(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Less than or equal to of series and other, element-wise (binary operator `le`).\n",
      " |      \n",
      " |      Equivalent to ``series <= other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  lt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Less than of series and other, element-wise (binary operator `lt`).\n",
      " |      \n",
      " |      Equivalent to ``series < other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=None, level=None)\n",
      " |      Return the mean absolute deviation of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : scalar or Series (if level specified)\n",
      " |  \n",
      " |  map(self, arg, na_action=None)\n",
      " |      Map values of Series using input correspondence (a dict, Series, or\n",
      " |      function).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg : function, dict, or Series\n",
      " |          Mapping correspondence.\n",
      " |      na_action : {None, 'ignore'}\n",
      " |          If 'ignore', propagate NA values, without passing them to the\n",
      " |          mapping correspondence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |          Same index as caller.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Map inputs to outputs (both of type `Series`):\n",
      " |      \n",
      " |      >>> x = pd.Series([1,2,3], index=['one', 'two', 'three'])\n",
      " |      >>> x\n",
      " |      one      1\n",
      " |      two      2\n",
      " |      three    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> y = pd.Series(['foo', 'bar', 'baz'], index=[1,2,3])\n",
      " |      >>> y\n",
      " |      1    foo\n",
      " |      2    bar\n",
      " |      3    baz\n",
      " |      \n",
      " |      >>> x.map(y)\n",
      " |      one   foo\n",
      " |      two   bar\n",
      " |      three baz\n",
      " |      \n",
      " |      If `arg` is a dictionary, return a new Series with values converted\n",
      " |      according to the dictionary's mapping:\n",
      " |      \n",
      " |      >>> z = {1: 'A', 2: 'B', 3: 'C'}\n",
      " |      \n",
      " |      >>> x.map(z)\n",
      " |      one   A\n",
      " |      two   B\n",
      " |      three C\n",
      " |      \n",
      " |      Use na_action to control whether NA values are affected by the mapping\n",
      " |      function.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, np.nan])\n",
      " |      \n",
      " |      >>> s2 = s.map('this is a string {}'.format, na_action=None)\n",
      " |      0    this is a string 1.0\n",
      " |      1    this is a string 2.0\n",
      " |      2    this is a string 3.0\n",
      " |      3    this is a string nan\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s3 = s.map('this is a string {}'.format, na_action='ignore')\n",
      " |      0    this is a string 1.0\n",
      " |      1    this is a string 2.0\n",
      " |      2    this is a string 3.0\n",
      " |      3                     NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.apply : For applying more complex functions on a Series.\n",
      " |      DataFrame.apply : Apply a function row-/column-wise.\n",
      " |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When `arg` is a dictionary, values in Series that are not in the\n",
      " |      dictionary (as keys) are converted to ``NaN``. However, if the\n",
      " |      dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.\n",
      " |      provides a method for default values), then this default is used\n",
      " |      rather than ``NaN``:\n",
      " |      \n",
      " |      >>> from collections import Counter\n",
      " |      >>> counter = Counter()\n",
      " |      >>> counter['bar'] += 1\n",
      " |      >>> y.map(counter)\n",
      " |      1    0\n",
      " |      2    1\n",
      " |      3    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the maximum of the values in the object.\n",
      " |                  If you want the *index* of the maximum, use ``idxmax``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      max : scalar or Series (if level specified)\n",
      " |  \n",
      " |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : scalar or Series (if level specified)\n",
      " |  \n",
      " |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : scalar or Series (if level specified)\n",
      " |  \n",
      " |  memory_usage(self, index=True, deep=False)\n",
      " |      Return the memory usage of the Series.\n",
      " |      \n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and of elements of `object` dtype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the Series index.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Bytes of memory consumed.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of the\n",
      " |          array.\n",
      " |      DataFrame.memory_usage : Bytes consumed by a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s.memory_usage()\n",
      " |      104\n",
      " |      \n",
      " |      Not including the index gives the size of the rest of the data, which\n",
      " |      is necessarily smaller:\n",
      " |      \n",
      " |      >>> s.memory_usage(index=False)\n",
      " |      24\n",
      " |      \n",
      " |      The memory footprint of `object` values is ignored by default:\n",
      " |      \n",
      " |      >>> s = pd.Series([\"a\", \"b\"])\n",
      " |      >>> s.values\n",
      " |      array(['a', 'b'], dtype=object)\n",
      " |      >>> s.memory_usage()\n",
      " |      96\n",
      " |      >>> s.memory_usage(deep=True)\n",
      " |      212\n",
      " |  \n",
      " |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the minimum of the values in the object.\n",
      " |                  If you want the *index* of the minimum, use ``idxmin``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      min : scalar or Series (if level specified)\n",
      " |  \n",
      " |  mod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Modulo of series and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``series % other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmod\n",
      " |  \n",
      " |  mode(self)\n",
      " |      Return the mode(s) of the dataset.\n",
      " |      \n",
      " |      Always returns Series even if only one value is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      modes : Series (sorted)\n",
      " |  \n",
      " |  mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmul\n",
      " |  \n",
      " |  multiply = mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmul\n",
      " |  \n",
      " |  ne(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Not equal to of series and other, element-wise (binary operator `ne`).\n",
      " |      \n",
      " |      Equivalent to ``series != other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  nlargest(self, n=5, keep='first')\n",
      " |      Return the largest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many descending sorted values\n",
      " |      keep : {'first', 'last'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      top_n : Series\n",
      " |          The n largest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n",
      " |      relative to the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nsmallest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(10**6))\n",
      " |      >>> s.nlargest(10)  # only sorts up to the N requested\n",
      " |      219921    4.644710\n",
      " |      82124     4.608745\n",
      " |      421689    4.564644\n",
      " |      425277    4.447014\n",
      " |      718691    4.414137\n",
      " |      43154     4.403520\n",
      " |      283187    4.313922\n",
      " |      595519    4.273635\n",
      " |      503969    4.250236\n",
      " |      121637    4.240952\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  nonzero(self)\n",
      " |      Return the *integer* indices of the elements that are non-zero\n",
      " |      \n",
      " |      This method is equivalent to calling `numpy.nonzero` on the\n",
      " |      series data. For compatibility with NumPy, the return value is\n",
      " |      the same (a tuple with an array of indices for each dimension),\n",
      " |      but it will always be a one-item tuple because series only have\n",
      " |      one dimension.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0, 3, 0, 4])\n",
      " |      >>> s.nonzero()\n",
      " |      (array([1, 3]),)\n",
      " |      >>> s.iloc[s.nonzero()[0]]\n",
      " |      1    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 3, 0, 4], index=['a', 'b', 'c', 'd'])\n",
      " |      # same return although index of s is different\n",
      " |      >>> s.nonzero()\n",
      " |      (array([1, 3]),)\n",
      " |      >>> s.iloc[s.nonzero()[0]]\n",
      " |      b    3\n",
      " |      d    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.nonzero\n",
      " |  \n",
      " |  notna(self)\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.notnull : alias of notna\n",
      " |      Series.isna : boolean inverse of notna\n",
      " |      Series.dropna : omit axes labels with missing values\n",
      " |      notna : top-level notna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  notnull(self)\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.notnull : alias of notna\n",
      " |      Series.isna : boolean inverse of notna\n",
      " |      Series.dropna : omit axes labels with missing values\n",
      " |      notna : top-level notna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  nsmallest(self, n=5, keep='first')\n",
      " |      Return the smallest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many ascending sorted values\n",
      " |      keep : {'first', 'last'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bottom_n : Series\n",
      " |          The n smallest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      " |      the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nlargest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(10**6))\n",
      " |      >>> s.nsmallest(10)  # only sorts up to the N requested\n",
      " |      288532   -4.954580\n",
      " |      732345   -4.835960\n",
      " |      64803    -4.812550\n",
      " |      446457   -4.609998\n",
      " |      501225   -4.483945\n",
      " |      669476   -4.472935\n",
      " |      973615   -4.401699\n",
      " |      621279   -4.355126\n",
      " |      773916   -4.347355\n",
      " |      359919   -4.331927\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  pow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Exponential power of series and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``series ** other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rpow\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the product of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded :: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : scalar or Series (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([]).prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the product of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded :: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : scalar or Series (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([]).prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  ptp(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Returns the difference between the maximum value and the\n",
      " |                  minimum value in the object. This is the equivalent of the\n",
      " |                  ``numpy.ndarray`` method ``ptp``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ptp : scalar or Series (if level specified)\n",
      " |  \n",
      " |  put(self, *args, **kwargs)\n",
      " |      Applies the `put` method to its `values` attribute\n",
      " |      if it has one.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.put\n",
      " |  \n",
      " |  quantile(self, q=0.5, interpolation='linear')\n",
      " |      Return value at the given quantile, a la numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          0 <= q <= 1, the quantile(s) to compute\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |              * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |                fractional part of the index surrounded by `i` and `j`.\n",
      " |              * lower: `i`.\n",
      " |              * higher: `j`.\n",
      " |              * nearest: `i` or `j` whichever is nearest.\n",
      " |              * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantile : float or Series\n",
      " |          if ``q`` is an array, a Series will be returned where the\n",
      " |          index is ``q`` and the values are the quantiles.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = Series([1, 2, 3, 4])\n",
      " |      >>> s.quantile(.5)\n",
      " |      2.5\n",
      " |      >>> s.quantile([.25, .5, .75])\n",
      " |      0.25    1.75\n",
      " |      0.50    2.50\n",
      " |      0.75    3.25\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.core.window.Rolling.quantile\n",
      " |  \n",
      " |  radd(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Addition of series and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.add\n",
      " |  \n",
      " |  ravel(self, order='C')\n",
      " |      Return the flattened underlying data as an ndarray\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.ravel\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.truediv\n",
      " |  \n",
      " |  reindex(self, index=None, **kwargs)\n",
      " |      Conform Series to new index with optional filling logic, placing\n",
      " |      NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      copy=False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      index : array-like, optional (should be specified using keywords)\n",
      " |          New labels / index to conform to. Preferably an Index object to\n",
      " |          avoid duplicating data\n",
      " |      \n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      " |          method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * default: don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap\n",
      " |      \n",
      " |      copy : boolean, default True\n",
      " |          Return a new object, even if the passed indexes are the same\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...      'http_status': [200,200,404,404,301],\n",
      " |      ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...       index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...             'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      We can also reindex the columns.\n",
      " |      \n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |      \n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to backpropagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29     100\n",
      " |      2009-12-30     100\n",
      " |      2009-12-31     100\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : Series\n",
      " |  \n",
      " |  reindex_axis(self, labels, axis=0, **kwargs)\n",
      " |      Conform Series to new index with optional filling logic.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use ``Series.reindex`` instead.\n",
      " |  \n",
      " |  rename(self, index=None, **kwargs)\n",
      " |      Alter Series index labels or name\n",
      " |      \n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |      \n",
      " |      Alternatively, change ``Series.name`` with a scalar value.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : scalar, hashable sequence, dict-like or function, optional\n",
      " |          dict-like or functions are transformations to apply to\n",
      " |          the index.\n",
      " |          Scalar or hashable sequence-like will alter the ``Series.name``\n",
      " |          attribute.\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to return a new Series. If True then value of copy is\n",
      " |          ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of a MultiIndex, only rename labels in the specified\n",
      " |          level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Series (new object)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.rename_axis\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename(\"my_name\") # scalar, changes Series.name\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      Name: my_name, dtype: int64\n",
      " |      >>> s.rename(lambda x: x ** 2)  # function, changes labels\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename({1: 3, 2: 5})  # mapping, changes labels\n",
      " |      0    1\n",
      " |      3    2\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  reorder_levels(self, order)\n",
      " |      Rearrange index levels using input order. May not drop or duplicate\n",
      " |      levels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int representing new level order.\n",
      " |             (reference level by number or key)\n",
      " |      axis : where to reorder levels\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller (new object)\n",
      " |  \n",
      " |  repeat(self, repeats, *args, **kwargs)\n",
      " |      Repeat elements of an Series. Refer to `numpy.ndarray.repeat`\n",
      " |      for more information about the `repeats` argument.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.repeat\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |      \n",
      " |      Values of the Series are replaced with other values dynamically.\n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |      \n",
      " |          * numeric, str or regex:\n",
      " |      \n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                for different existing values. For example,\n",
      " |                ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                'y' with 'z'. To use a dict in this way the `value`\n",
      " |                parameter should be `None`.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                should be replaced in different columns. For example,\n",
      " |                ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                and the value 'z' in column 'b' and replaces these values\n",
      " |                with whatever is specified in `value`. The `value` parameter\n",
      " |                should not be ``None`` in this case. You can treat this as a\n",
      " |                special case of passing two lists except that you are\n",
      " |                specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                'a' for the value 'b' and replace it with NaN. The `value`\n",
      " |                parameter should be ``None`` to use a nested dict in this\n",
      " |                way. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or\n",
      " |                Series of such elements. If `value` is also ``None`` then\n",
      " |                this **must** be a nested dictionary or Series.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |      inplace : boolean, default False\n",
      " |          If True, in place. Note: this will modify any\n",
      " |          other views on this object (e.g. a column from a DataFrame).\n",
      " |          Returns the caller if this is True.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill', `None`}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |              Added to DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna : Fill NA values\n",
      " |      Series.where : Replace values based on boolean condition\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Object after replacement.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |            ``None``.\n",
      " |      TypeError\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |            into a regular expression or is a list, dict, ndarray, or\n",
      " |            Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |            the arguments to `to_replace` does not match the type of the\n",
      " |            value being replaced\n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |            `value` but they are not the same length.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point\n",
      " |        numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |        key(s) in the dict are the to_replace part and\n",
      " |        value(s) in the dict are the value parameter.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, 2, 3, 4])\n",
      " |      >>> s.replace(0, 5)\n",
      " |      0    5\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |         A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      **List-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    0\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dict-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |           A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |           A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |           A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |      \n",
      " |      **Regular expression `to_replace`**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex={r'^ba.$':'new', 'foo':'xyz'})\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      Note that when replacing multiple ``bool`` or ``datetime64`` objects,\n",
      " |      the data types in the `to_replace` parameter must match the data\n",
      " |      type of the value being replaced:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [True, False, True],\n",
      " |      ...                    'B': [False, True, False]})\n",
      " |      >>> df.replace({'a string': 'new value', True: False})  # raises\n",
      " |      Traceback (most recent call last):\n",
      " |          ...\n",
      " |      TypeError: Cannot compare types 'ndarray(dtype=bool)' and 'str'\n",
      " |      \n",
      " |      This raises a ``TypeError`` because one of the ``dict`` keys is not of\n",
      " |      the correct type for replacement.\n",
      " |      \n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the pecularities\n",
      " |      of the `to_replace` parameter:\n",
      " |      \n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |      \n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |      \n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |      When ``value=None`` and `to_replace` is a scalar, list or\n",
      " |      tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |      The command ``s.replace('a', None)`` is actually equivalent to\n",
      " |      ``s.replace(to_replace='a', value=None, method='pad')``:\n",
      " |      \n",
      " |      >>> s.replace('a', None)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |  \n",
      " |  reset_index(self, level=None, drop=False, name=None, inplace=False)\n",
      " |      Generate a new DataFrame or Series with the index reset.\n",
      " |      \n",
      " |      This is useful when the index needs to be treated as a column, or\n",
      " |      when the index is meaningless and needs to be reset to the default\n",
      " |      before another operation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default optional\n",
      " |          For a Series with a MultiIndex, only remove the specified levels\n",
      " |          from the index. Removes all levels by default.\n",
      " |      drop : bool, default False\n",
      " |          Just reset the index, without inserting it as a column in\n",
      " |          the new DataFrame.\n",
      " |      name : object, optional\n",
      " |          The name to use for the column containing the original Series\n",
      " |          values. Uses ``self.name`` by default. This argument is ignored\n",
      " |          when `drop` is True.\n",
      " |      inplace : bool, default False\n",
      " |          Modify the Series in place (do not create a new object).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          When `drop` is False (the default), a DataFrame is returned.\n",
      " |          The newly created columns will come first in the DataFrame,\n",
      " |          followed by the original Series values.\n",
      " |          When `drop` is True, a `Series` is returned.\n",
      " |          In either case, if ``inplace=True``, no value is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.reset_index: Analogous function for DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4], name='foo',\n",
      " |      ...               index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))\n",
      " |      \n",
      " |      Generate a DataFrame with default index.\n",
      " |      \n",
      " |      >>> s.reset_index()\n",
      " |        idx  foo\n",
      " |      0   a    1\n",
      " |      1   b    2\n",
      " |      2   c    3\n",
      " |      3   d    4\n",
      " |      \n",
      " |      To specify the name of the new column use `name`.\n",
      " |      \n",
      " |      >>> s.reset_index(name='values')\n",
      " |        idx  values\n",
      " |      0   a       1\n",
      " |      1   b       2\n",
      " |      2   c       3\n",
      " |      3   d       4\n",
      " |      \n",
      " |      To generate a new Series with the default set `drop` to True.\n",
      " |      \n",
      " |      >>> s.reset_index(drop=True)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      Name: foo, dtype: int64\n",
      " |      \n",
      " |      To update the Series in place, without generating a new one\n",
      " |      set `inplace` to True. Note that it also requires ``drop=True``.\n",
      " |      \n",
      " |      >>> s.reset_index(inplace=True, drop=True)\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      Name: foo, dtype: int64\n",
      " |      \n",
      " |      The `level` parameter is interesting for Series with a multi-level\n",
      " |      index.\n",
      " |      \n",
      " |      >>> arrays = [np.array(['bar', 'bar', 'baz', 'baz']),\n",
      " |      ...           np.array(['one', 'two', 'one', 'two'])]\n",
      " |      >>> s2 = pd.Series(\n",
      " |      ...     range(4), name='foo',\n",
      " |      ...     index=pd.MultiIndex.from_arrays(arrays,\n",
      " |      ...                                     names=['a', 'b']))\n",
      " |      \n",
      " |      To remove a specific level from the Index, use `level`.\n",
      " |      \n",
      " |      >>> s2.reset_index(level='a')\n",
      " |             a  foo\n",
      " |      b\n",
      " |      one  bar    0\n",
      " |      two  bar    1\n",
      " |      one  baz    2\n",
      " |      two  baz    3\n",
      " |      \n",
      " |      If `level` is not set, all levels are removed from the Index.\n",
      " |      \n",
      " |      >>> s2.reset_index()\n",
      " |           a    b  foo\n",
      " |      0  bar  one    0\n",
      " |      1  bar  two    1\n",
      " |      2  baz  one    2\n",
      " |      3  baz  two    3\n",
      " |  \n",
      " |  rfloordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division of series and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.floordiv\n",
      " |  \n",
      " |  rmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Modulo of series and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.mod\n",
      " |  \n",
      " |  rmul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.mul\n",
      " |  \n",
      " |  rolling(self, window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None)\n",
      " |      Provides rolling window calculations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, or offset\n",
      " |          Size of the moving window. This is the number of observations used for\n",
      " |          calculating the statistic. Each window will be a fixed size.\n",
      " |      \n",
      " |          If its an offset then this will be the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes. This is\n",
      " |          new in 0.19.0\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA). For a window that is specified by an offset,\n",
      " |          this will default to 1.\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      win_type : string, default None\n",
      " |          Provide a window type. If ``None``, all points are evenly weighted.\n",
      " |          See the notes below for further information.\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column on which to calculate\n",
      " |          the rolling window, rather than the index\n",
      " |      closed : string, default None\n",
      " |          Make the interval closed on the 'right', 'left', 'both' or\n",
      " |          'neither' endpoints.\n",
      " |          For offset-based windows, it defaults to 'right'.\n",
      " |          For fixed windows, defaults to 'both'. Remaining cases not implemented\n",
      " |          for fixed windows.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window or Rolling sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'triang'\n",
      " |      window type.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='triang').sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  2.5\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, min_periods defaults\n",
      " |      to the window length.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Same as above, but explicitly set the min_periods\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                   index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      \n",
      " |      Contrasting to an integer rolling window, this will roll a variable\n",
      " |      length window corresponding to the time period.\n",
      " |      The default for min_periods is 1.\n",
      " |      \n",
      " |      >>> df.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      To learn more about the offsets & frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      The recognized win_types are:\n",
      " |      \n",
      " |      * ``boxcar``\n",
      " |      * ``triang``\n",
      " |      * ``blackman``\n",
      " |      * ``hamming``\n",
      " |      * ``bartlett``\n",
      " |      * ``parzen``\n",
      " |      * ``bohman``\n",
      " |      * ``blackmanharris``\n",
      " |      * ``nuttall``\n",
      " |      * ``barthann``\n",
      " |      * ``kaiser`` (needs beta)\n",
      " |      * ``gaussian`` (needs std)\n",
      " |      * ``general_gaussian`` (needs power, width)\n",
      " |      * ``slepian`` (needs width).\n",
      " |      \n",
      " |      If ``win_type=None`` all points are evenly weighted. To learn more about\n",
      " |      different window types see `scipy.signal window functions\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/signal.html#window-functions>`__.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions\n",
      " |  \n",
      " |  round(self, decimals=0, *args, **kwargs)\n",
      " |      Round each value in a Series to the given number of decimals.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int\n",
      " |          Number of decimal places to round to (default: 0).\n",
      " |          If decimals is negative, it specifies the number of\n",
      " |          positions to the left of the decimal point.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around\n",
      " |      DataFrame.round\n",
      " |  \n",
      " |  rpow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Exponential power of series and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.pow\n",
      " |  \n",
      " |  rsub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.sub\n",
      " |  \n",
      " |  rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.truediv\n",
      " |  \n",
      " |  searchsorted(self, value, side='left', sorter=None)\n",
      " |      Find indices where elements should be inserted to maintain order.\n",
      " |      \n",
      " |      Find the indices into a sorted Series `self` such that, if the\n",
      " |      corresponding elements in `value` were inserted before the indices,\n",
      " |      the order of `self` would be preserved.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : array_like\n",
      " |          Values to insert into `self`.\n",
      " |      side : {'left', 'right'}, optional\n",
      " |          If 'left', the index of the first suitable location found is given.\n",
      " |          If 'right', return the last such index.  If there is no suitable\n",
      " |          index, return either 0 or N (where N is the length of `self`).\n",
      " |      sorter : 1-D array_like, optional\n",
      " |          Optional array of integer indices that sort `self` into ascending\n",
      " |          order. They are typically the result of ``np.argsort``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indices : array of ints\n",
      " |          Array of insertion points with the same shape as `value`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.searchsorted\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Binary search is used to find the required insertion points.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> x = pd.Series([1, 2, 3])\n",
      " |      >>> x\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> x.searchsorted(4)\n",
      " |      array([3])\n",
      " |      \n",
      " |      >>> x.searchsorted([0, 4])\n",
      " |      array([0, 3])\n",
      " |      \n",
      " |      >>> x.searchsorted([1, 3], side='left')\n",
      " |      array([0, 2])\n",
      " |      \n",
      " |      >>> x.searchsorted([1, 3], side='right')\n",
      " |      array([1, 3])\n",
      " |      \n",
      " |      >>> x = pd.Categorical(['apple', 'bread', 'bread',\n",
      " |                              'cheese', 'milk'], ordered=True)\n",
      " |      [apple, bread, bread, cheese, milk]\n",
      " |      Categories (4, object): [apple < bread < cheese < milk]\n",
      " |      \n",
      " |      >>> x.searchsorted('bread')\n",
      " |      array([1])     # Note: an array, not a scalar\n",
      " |      \n",
      " |      >>> x.searchsorted(['bread'], side='right')\n",
      " |      array([3])\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sem : scalar or Series (if level specified)\n",
      " |  \n",
      " |  set_value(self, label, value, takeable=False)\n",
      " |      Quickly set single value at passed label. If label is not contained,\n",
      " |      a new object is created with the label placed at the end of the result\n",
      " |      index.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Please use .at[] or .iat[] accessors.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |          Partial indexing with MultiIndex not allowed\n",
      " |      value : object\n",
      " |          Scalar value\n",
      " |      takeable : interpret the index as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      series : Series\n",
      " |          If label is contained, will be reference to calling Series,\n",
      " |          otherwise a new object\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift index by desired number of periods with an optional time freq\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, optional\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          See Notes.\n",
      " |      axis : {0 or 'index'}\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is specified then the index values are shifted but the data\n",
      " |      is not realigned. That is, use freq if you would like to extend the\n",
      " |      index when shifting and preserve the original data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Series\n",
      " |  \n",
      " |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : scalar or Series (if level specified)\n",
      " |  \n",
      " |  sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True)\n",
      " |      Sort Series by index labels.\n",
      " |      \n",
      " |      Returns a new Series sorted by label if `inplace` argument is\n",
      " |      ``False``, otherwise updates the original series and returns None.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int, default 0\n",
      " |          Axis to direct sorting. This can only be 0 for Series.\n",
      " |      level : int, optional\n",
      " |          If not None, sort on values in specified index level(s).\n",
      " |      ascending : bool, default true\n",
      " |          Sort ascending vs. descending.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information.  'mergesort' is the only stable algorithm. For\n",
      " |          DataFrames, this option is only applied when sorting on a single\n",
      " |          column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |          If 'first' puts NaNs at the beginning, 'last' puts NaNs at the end.\n",
      " |          Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          If true and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The original Series sorted by the labels\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index: Sort DataFrame by the index\n",
      " |      DataFrame.sort_values: Sort DataFrame by the value\n",
      " |      Series.sort_values : Sort Series by the value\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, 4])\n",
      " |      >>> s.sort_index()\n",
      " |      1    c\n",
      " |      2    b\n",
      " |      3    a\n",
      " |      4    d\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Sort Descending\n",
      " |      \n",
      " |      >>> s.sort_index(ascending=False)\n",
      " |      4    d\n",
      " |      3    a\n",
      " |      2    b\n",
      " |      1    c\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Sort Inplace\n",
      " |      \n",
      " |      >>> s.sort_index(inplace=True)\n",
      " |      >>> s\n",
      " |      1    c\n",
      " |      2    b\n",
      " |      3    a\n",
      " |      4    d\n",
      " |      dtype: object\n",
      " |      \n",
      " |      By default NaNs are put at the end, but use `na_position` to place\n",
      " |      them at the beginning\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, np.nan])\n",
      " |      >>> s.sort_index(na_position='first')\n",
      " |      NaN     d\n",
      " |       1.0    c\n",
      " |       2.0    b\n",
      " |       3.0    a\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Specify index level to sort\n",
      " |      \n",
      " |      >>> arrays = [np.array(['qux', 'qux', 'foo', 'foo',\n",
      " |      ...                     'baz', 'baz', 'bar', 'bar']),\n",
      " |      ...           np.array(['two', 'one', 'two', 'one',\n",
      " |      ...                     'two', 'one', 'two', 'one'])]\n",
      " |      >>> s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8], index=arrays)\n",
      " |      >>> s.sort_index(level=1)\n",
      " |      bar  one    8\n",
      " |      baz  one    6\n",
      " |      foo  one    4\n",
      " |      qux  one    2\n",
      " |      bar  two    7\n",
      " |      baz  two    5\n",
      " |      foo  two    3\n",
      " |      qux  two    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Does not sort by remaining levels when sorting by levels\n",
      " |      \n",
      " |      >>> s.sort_index(level=1, sort_remaining=False)\n",
      " |      qux  one    2\n",
      " |      foo  one    4\n",
      " |      baz  one    6\n",
      " |      bar  one    8\n",
      " |      qux  two    1\n",
      " |      foo  two    3\n",
      " |      baz  two    5\n",
      " |      bar  two    7\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  sort_values(self, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      " |      Sort by the values.\n",
      " |      \n",
      " |      Sort a Series in ascending or descending order by some\n",
      " |      criterion.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}, default 0\n",
      " |          Axis to direct sorting. The value 'index' is accepted for\n",
      " |          compatibility with DataFrame.sort_values.\n",
      " |      ascending : bool, default True\n",
      " |          If True, sort values in ascending order, otherwise descending.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort' or 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information. 'mergesort' is the only stable  algorithm.\n",
      " |      na_position : {'first' or 'last'}, default 'last'\n",
      " |          Argument 'first' puts NaNs at the beginning, 'last' puts NaNs at\n",
      " |          the end.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series ordered by values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index : Sort by the Series indices.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values along either axis.\n",
      " |      DataFrame.sort_index : Sort DataFrame by indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([np.nan, 1, 3, 10, 5])\n",
      " |      >>> s\n",
      " |      0     NaN\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      3     10.0\n",
      " |      4     5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values ascending order (default behaviour)\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=True)\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      4     5.0\n",
      " |      3    10.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values descending order\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=False)\n",
      " |      3    10.0\n",
      " |      4     5.0\n",
      " |      2     3.0\n",
      " |      1     1.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values inplace\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=False, inplace=True)\n",
      " |      >>> s\n",
      " |      3    10.0\n",
      " |      4     5.0\n",
      " |      2     3.0\n",
      " |      1     1.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values putting NAs first\n",
      " |      \n",
      " |      >>> s.sort_values(na_position='first')\n",
      " |      0     NaN\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      4     5.0\n",
      " |      3    10.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort a series of strings\n",
      " |      \n",
      " |      >>> s = pd.Series(['z', 'b', 'd', 'a', 'c'])\n",
      " |      >>> s\n",
      " |      0    z\n",
      " |      1    b\n",
      " |      2    d\n",
      " |      3    a\n",
      " |      4    c\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s.sort_values()\n",
      " |      3    a\n",
      " |      1    b\n",
      " |      4    c\n",
      " |      2    d\n",
      " |      0    z\n",
      " |      dtype: object\n",
      " |  \n",
      " |  sortlevel(self, level=0, ascending=True, sort_remaining=True)\n",
      " |      Sort Series with MultiIndex by chosen level. Data will be\n",
      " |      lexicographically sorted by the chosen level followed by the other\n",
      " |      levels (in order),\n",
      " |      \n",
      " |      .. deprecated:: 0.20.0\n",
      " |          Use :meth:`Series.sort_index`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |      ascending : bool, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index(level=...)\n",
      " |  \n",
      " |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : scalar or Series (if level specified)\n",
      " |  \n",
      " |  sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rsub\n",
      " |  \n",
      " |  subtract = sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rsub\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the sum of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded :: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sum : scalar or Series (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  swaplevel(self, i=-2, j=-1, copy=True)\n",
      " |      Swap levels i and j in a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int, string (can be mixed)\n",
      " |          Level of index to be swapped. Can pass level name as string.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      swapped : Series\n",
      " |      \n",
      " |      .. versionchanged:: 0.18.1\n",
      " |      \n",
      " |         The indexes ``i`` and ``j`` are now optional, and default to\n",
      " |         the two innermost levels of the index.\n",
      " |  \n",
      " |  to_csv(self, path=None, index=True, sep=',', na_rep='', float_format=None, header=False, index_label=None, mode='w', encoding=None, compression=None, date_format=None, decimal='.')\n",
      " |      Write Series to a comma-separated values (csv) file\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string or file handle, default None\n",
      " |          File path or object, if None is provided the result is returned as\n",
      " |          a string.\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      header : boolean, default False\n",
      " |          Write out series name\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      mode : Python write mode, default 'w'\n",
      " |      sep : character, default \",\"\n",
      " |          Field delimiter for the output file.\n",
      " |      encoding : string, optional\n",
      " |          a string representing the encoding to use if the contents are\n",
      " |          non-ascii, for python versions prior to 3\n",
      " |      compression : string, optional\n",
      " |          A string representing the compression to use in the output file.\n",
      " |          Allowed values are 'gzip', 'bz2', 'zip', 'xz'. This input is only\n",
      " |          used when the first argument is a filename.\n",
      " |      date_format: string, default None\n",
      " |          Format string for datetime objects.\n",
      " |      decimal: string, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data\n",
      " |  \n",
      " |  to_dict(self, into=<class 'dict'>)\n",
      " |      Convert Series to {label -> value} dict or dict-like object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      into : class, default dict\n",
      " |          The collections.Mapping subclass to use as the return\n",
      " |          object. Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value_dict : collections.Mapping\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_dict()\n",
      " |      {0: 1, 1: 2, 2: 3, 3: 4}\n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> s.to_dict(OrderedDict)\n",
      " |      OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> s.to_dict(dd)\n",
      " |      defaultdict(<type 'list'>, {0: 1, 1: 2, 2: 3, 3: 4})\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True)\n",
      " |      Write Series to an excel sheet\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : string or ExcelWriter object\n",
      " |          File path or existing ExcelWriter\n",
      " |      sheet_name : string, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write\n",
      " |      header : boolean or list of string, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow :\n",
      " |          upper left cell row to dump data frame\n",
      " |      startcol :\n",
      " |          upper left cell column to dump data frame\n",
      " |      engine : string, default None\n",
      " |          write engine to use - you can also set this via the options\n",
      " |          ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      merge_cells : boolean, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding: string, default None\n",
      " |          encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      inf_rep : string, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel)\n",
      " |      freeze_panes : tuple of integer (length 2), default None\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If passing an existing ExcelWriter object, then the sheet will be added\n",
      " |      to the existing workbook.  This can be used to save different\n",
      " |      DataFrames to one workbook:\n",
      " |      \n",
      " |      >>> writer = pd.ExcelWriter('output.xlsx')\n",
      " |      >>> df1.to_excel(writer,'Sheet1')\n",
      " |      >>> df2.to_excel(writer,'Sheet2')\n",
      " |      >>> writer.save()\n",
      " |      \n",
      " |      For compatibility with to_csv, to_excel serializes lists and dicts to\n",
      " |      strings before writing.\n",
      " |  \n",
      " |  to_frame(self, name=None)\n",
      " |      Convert Series to DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object, default None\n",
      " |          The passed name should substitute for the series name (if it has\n",
      " |          one).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      data_frame : DataFrame\n",
      " |  \n",
      " |  to_period(self, freq=None, copy=True)\n",
      " |      Convert Series from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : Series with PeriodIndex\n",
      " |  \n",
      " |  to_sparse(self, kind='block', fill_value=None)\n",
      " |      Convert Series to SparseSeries\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kind : {'block', 'integer'}\n",
      " |      fill_value : float, defaults to NaN (missing)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sp : SparseSeries\n",
      " |  \n",
      " |  to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None)\n",
      " |      Render a string representation of the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : StringIO-like, optional\n",
      " |          buffer to write to\n",
      " |      na_rep : string, optional\n",
      " |          string representation of NAN to use, default 'NaN'\n",
      " |      float_format : one-parameter function, optional\n",
      " |          formatter function to apply to columns' elements if they are floats\n",
      " |          default None\n",
      " |      header: boolean, default True\n",
      " |          Add the Series header (index name)\n",
      " |      index : bool, optional\n",
      " |          Add index (row) labels, default True\n",
      " |      length : boolean, default False\n",
      " |          Add the Series length\n",
      " |      dtype : boolean, default False\n",
      " |          Add the Series dtype\n",
      " |      name : boolean, default False\n",
      " |          Add the Series name if not None\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to show before truncating. If None, show\n",
      " |          all.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      formatted : string (if not buffer passed)\n",
      " |  \n",
      " |  to_timestamp(self, freq=None, how='start', copy=True)\n",
      " |      Cast to datetimeindex of timestamps, at *beginning* of period\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default frequency of PeriodIndex\n",
      " |          Desired frequency\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : Series with DatetimeIndex\n",
      " |  \n",
      " |  transform(self, func, *args, **kwargs)\n",
      " |      Call function producing a like-indexed NDFrame\n",
      " |      and return a NDFrame with the transformed values\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, string, dictionary, or list of string/callables\n",
      " |          To apply to column\n",
      " |      \n",
      " |          Accepted Combinations are:\n",
      " |      \n",
      " |          - string function name\n",
      " |          - function\n",
      " |          - list of functions\n",
      " |          - dict of column names -> functions (or list of functions)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      transformed : NDFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      " |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      " |      df.iloc[3:7] = np.nan\n",
      " |      \n",
      " |      >>> df.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |                         A         B         C\n",
      " |      2000-01-01  0.579457  1.236184  0.123424\n",
      " |      2000-01-02  0.370357 -0.605875 -1.231325\n",
      " |      2000-01-03  1.455756 -0.277446  0.288967\n",
      " |      2000-01-04       NaN       NaN       NaN\n",
      " |      2000-01-05       NaN       NaN       NaN\n",
      " |      2000-01-06       NaN       NaN       NaN\n",
      " |      2000-01-07       NaN       NaN       NaN\n",
      " |      2000-01-08 -0.498658  1.274522  1.642524\n",
      " |      2000-01-09 -0.540524 -1.012676 -0.828968\n",
      " |      2000-01-10 -1.366388 -0.614710  0.005378\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.NDFrame.aggregate\n",
      " |      pandas.NDFrame.apply\n",
      " |  \n",
      " |  truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  unique(self)\n",
      " |      Return unique values of Series object.\n",
      " |      \n",
      " |      Uniques are returned in order of appearance. Hash table-based unique,\n",
      " |      therefore does NOT sort.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray or Categorical\n",
      " |          The unique values returned as a NumPy array. In case of categorical\n",
      " |          data type, returned as a Categorical.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.unique : top-level unique method for any 1-d array-like object.\n",
      " |      Index.unique : return Index with unique values from an Index object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([2, 1, 3, 3], name='A').unique()\n",
      " |      array([2, 1, 3])\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()\n",
      " |      array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')\n",
      " |      ...            for _ in range(3)]).unique()\n",
      " |      array([Timestamp('2016-01-01 00:00:00-0500', tz='US/Eastern')],\n",
      " |            dtype=object)\n",
      " |      \n",
      " |      An unordered Categorical will return categories in the order of\n",
      " |      appearance.\n",
      " |      \n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'))).unique()\n",
      " |      [b, a, c]\n",
      " |      Categories (3, object): [b, a, c]\n",
      " |      \n",
      " |      An ordered Categorical preserves the category ordering.\n",
      " |      \n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),\n",
      " |      ...                          ordered=True)).unique()\n",
      " |      [b, a, c]\n",
      " |      Categories (3, object): [a < b < c]\n",
      " |  \n",
      " |  unstack(self, level=-1, fill_value=None)\n",
      " |      Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.\n",
      " |      The level involved will automatically get sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, string, or list of these, default last level\n",
      " |          Level(s) to unstack, can pass level name\n",
      " |      fill_value : replace NaN with this value if the unstack produces\n",
      " |          missing values\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4],\n",
      " |      ...     index=pd.MultiIndex.from_product([['one', 'two'], ['a', 'b']]))\n",
      " |      >>> s\n",
      " |      one  a    1\n",
      " |           b    2\n",
      " |      two  a    3\n",
      " |           b    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a  b\n",
      " |      one  1  2\n",
      " |      two  3  4\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a    1    3\n",
      " |      b    2    4\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unstacked : DataFrame\n",
      " |  \n",
      " |  update(self, other)\n",
      " |      Modify Series in place using non-NA values from passed\n",
      " |      Series. Aligns on index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, 5, 6]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'b', 'c'])\n",
      " |      >>> s.update(pd.Series(['d', 'e'], index=[0, 2]))\n",
      " |      >>> s\n",
      " |      0    d\n",
      " |      1    b\n",
      " |      2    e\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, 5, 6, 7, 8]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      If ``other`` contains NaNs the corresponding values are not updated\n",
      " |      in the original Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, np.nan, 6]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    2\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  valid(self, inplace=False, **kwargs)\n",
      " |      Return Series without null values.\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |          Use :meth:`Series.dropna` instead.\n",
      " |  \n",
      " |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : scalar or Series (if level specified)\n",
      " |  \n",
      " |  view(self, dtype=None)\n",
      " |      Create a new view of the Series.\n",
      " |      \n",
      " |      This function will return a new Series with a view of the same\n",
      " |      underlying values in memory, optionally reinterpreted with a new data\n",
      " |      type. The new data type must preserve the same size in bytes as to not\n",
      " |      cause index misalignment.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type\n",
      " |          Data type object or one of their string representations.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A new Series object as a view of the same data in memory.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.view : Equivalent numpy function to create a new view of\n",
      " |          the same data in memory.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Series are instantiated with ``dtype=float64`` by default. While\n",
      " |      ``numpy.ndarray.view()`` will return a view with the same data type as\n",
      " |      the original array, ``Series.view()`` (without specified dtype)\n",
      " |      will try using ``float64`` and may fail if the original data type size\n",
      " |      in bytes is not the same.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([-2, -1, 0, 1, 2], dtype='int8')\n",
      " |      >>> s\n",
      " |      0   -2\n",
      " |      1   -1\n",
      " |      2    0\n",
      " |      3    1\n",
      " |      4    2\n",
      " |      dtype: int8\n",
      " |      \n",
      " |      The 8 bit signed integer representation of `-1` is `0b11111111`, but\n",
      " |      the same bytes represent 255 if read as an 8 bit unsigned integer:\n",
      " |      \n",
      " |      >>> us = s.view('uint8')\n",
      " |      >>> us\n",
      " |      0    254\n",
      " |      1    255\n",
      " |      2      0\n",
      " |      3      1\n",
      " |      4      2\n",
      " |      dtype: uint8\n",
      " |      \n",
      " |      The views share the same underlying values:\n",
      " |      \n",
      " |      >>> us[0] = 128\n",
      " |      >>> s\n",
      " |      0   -128\n",
      " |      1     -1\n",
      " |      2      0\n",
      " |      3      1\n",
      " |      4      2\n",
      " |      dtype: int8\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pandas.core.series.Series:\n",
      " |  \n",
      " |  from_array(arr, index=None, name=None, dtype=None, copy=False, fastpath=False) from builtins.type\n",
      " |      Construct Series from array.\n",
      " |      \n",
      " |      .. deprecated :: 0.23.0\n",
      " |          Use pd.Series(..) constructor instead.\n",
      " |  \n",
      " |  from_csv(path, sep=',', parse_dates=True, header=None, index_col=0, encoding=None, infer_datetime_format=False) from builtins.type\n",
      " |      Read CSV file.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use :func:`pandas.read_csv` instead.\n",
      " |      \n",
      " |      It is preferable to use the more powerful :func:`pandas.read_csv`\n",
      " |      for most general purposes, but ``from_csv`` makes for an easy\n",
      " |      roundtrip to and from a file (the exact counterpart of\n",
      " |      ``to_csv``), especially with a time Series.\n",
      " |      \n",
      " |      This method only differs from :func:`pandas.read_csv` in some defaults:\n",
      " |      \n",
      " |      - `index_col` is ``0`` instead of ``None`` (take first column as index\n",
      " |        by default)\n",
      " |      - `header` is ``None`` instead of ``0`` (the first row is not used as\n",
      " |        the column names)\n",
      " |      - `parse_dates` is ``True`` instead of ``False`` (try parsing the index\n",
      " |        as datetime by default)\n",
      " |      \n",
      " |      With :func:`pandas.read_csv`, the option ``squeeze=True`` can be used\n",
      " |      to return a Series like ``from_csv``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string file path or file handle / StringIO\n",
      " |      sep : string, default ','\n",
      " |          Field delimiter\n",
      " |      parse_dates : boolean, default True\n",
      " |          Parse dates. Different default from read_table\n",
      " |      header : int, default None\n",
      " |          Row to use as header (skip prior rows)\n",
      " |      index_col : int or sequence, default 0\n",
      " |          Column to use for index. If a sequence is given, a MultiIndex\n",
      " |          is used. Different default from read_table\n",
      " |      encoding : string, optional\n",
      " |          a string representing the encoding to use if the contents are\n",
      " |          non-ascii, for python versions prior to 3\n",
      " |      infer_datetime_format: boolean, default False\n",
      " |          If True and `parse_dates` is True for a column, try to infer the\n",
      " |          datetime format based on the first datetime string. If the format\n",
      " |          can be inferred, there often will be a large parsing speed-up.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.read_csv\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.series.Series:\n",
      " |  \n",
      " |  asobject\n",
      " |      Return object Series which contains boxed values.\n",
      " |      \n",
      " |      .. deprecated :: 0.23.0\n",
      " |      \n",
      " |         Use ``astype(object)`` instead.\n",
      " |      \n",
      " |      *this is an internal non-public method*\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list of the row axis labels\n",
      " |  \n",
      " |  dtype\n",
      " |      return the dtype object of the underlying data\n",
      " |  \n",
      " |  dtypes\n",
      " |      return the dtype object of the underlying data\n",
      " |  \n",
      " |  ftype\n",
      " |      return if the data is sparse|dense\n",
      " |  \n",
      " |  ftypes\n",
      " |      return if the data is sparse|dense\n",
      " |  \n",
      " |  imag\n",
      " |  \n",
      " |  index\n",
      " |      The index (axis labels) of the Series.\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  real\n",
      " |  \n",
      " |  values\n",
      " |      Return Series as ndarray or ndarray-like\n",
      " |      depending on the dtype\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr : numpy.ndarray or ndarray-like\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([1, 2, 3]).values\n",
      " |      array([1, 2, 3])\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).values\n",
      " |      array(['a', 'a', 'b', 'c'], dtype=object)\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).astype('category').values\n",
      " |      [a, a, b, c]\n",
      " |      Categories (3, object): [a, b, c]\n",
      " |      \n",
      " |      Timezone aware datetime data is converted to UTC:\n",
      " |      \n",
      " |      >>> pd.Series(pd.date_range('20130101', periods=3,\n",
      " |      ...                         tz='US/Eastern')).values\n",
      " |      array(['2013-01-01T05:00:00.000000000',\n",
      " |             '2013-01-02T05:00:00.000000000',\n",
      " |             '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.series.Series:\n",
      " |  \n",
      " |  cat = <class 'pandas.core.arrays.categorical.CategoricalAccessor'>\n",
      " |      Accessor object for categorical properties of the Series values.\n",
      " |      \n",
      " |      Be aware that assigning to `categories` is a inplace operation, while all\n",
      " |      methods return new categorical data per default (but can be called with\n",
      " |      `inplace=True`).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or CategoricalIndex\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.cat.categories\n",
      " |      >>> s.cat.categories = list('abc')\n",
      " |      >>> s.cat.rename_categories(list('cab'))\n",
      " |      >>> s.cat.reorder_categories(list('cab'))\n",
      " |      >>> s.cat.add_categories(['d','e'])\n",
      " |      >>> s.cat.remove_categories(['d'])\n",
      " |      >>> s.cat.remove_unused_categories()\n",
      " |      >>> s.cat.set_categories(list('abcde'))\n",
      " |      >>> s.cat.as_ordered()\n",
      " |      >>> s.cat.as_unordered()\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.SeriesPlotMethods'>\n",
      " |      Series plotting accessor and method\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.plot.line()\n",
      " |      >>> s.plot.bar()\n",
      " |      >>> s.plot.hist()\n",
      " |      \n",
      " |      Plotting methods can also be accessed by calling the accessor as a method\n",
      " |      with the ``kind`` argument:\n",
      " |      ``s.plot(kind='line')`` is equivalent to ``s.plot.line()``\n",
      " |  \n",
      " |  str = <class 'pandas.core.strings.StringMethods'>\n",
      " |      Vectorized string functions for Series and Index. NAs stay NA unless\n",
      " |      handled otherwise by a particular method. Patterned after Python's string\n",
      " |      methods, with some inspiration from R's stringr package.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.str.split('_')\n",
      " |      >>> s.str.replace('_', '')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return an iterator of the values.\n",
      " |      \n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |  \n",
      " |  factorize(self, sort=False, na_sentinel=-1)\n",
      " |      Encode the object as an enumerated type or categorical variable.\n",
      " |      \n",
      " |      This method is useful for obtaining a numeric representation of an\n",
      " |      array when all that matters is identifying distinct values. `factorize`\n",
      " |      is available as both a top-level function :func:`pandas.factorize`,\n",
      " |      and as a method :meth:`Series.factorize` and :meth:`Index.factorize`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sort : boolean, default False\n",
      " |          Sort `uniques` and shuffle `labels` to maintain the\n",
      " |          relationship.\n",
      " |      \n",
      " |      na_sentinel : int, default -1\n",
      " |          Value to mark \"not found\".\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : ndarray\n",
      " |          An integer ndarray that's an indexer into `uniques`.\n",
      " |          ``uniques.take(labels)`` will have the same values as `values`.\n",
      " |      uniques : ndarray, Index, or Categorical\n",
      " |          The unique valid values. When `values` is Categorical, `uniques`\n",
      " |          is a Categorical. When `values` is some other pandas object, an\n",
      " |          `Index` is returned. Otherwise, a 1-D ndarray is returned.\n",
      " |      \n",
      " |          .. note ::\n",
      " |      \n",
      " |             Even if there's a missing value in `values`, `uniques` will\n",
      " |             *not* contain an entry for it.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.cut : Discretize continuous-valued array.\n",
      " |      pandas.unique : Find the unique valuse in an array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      These examples all show factorize as a top-level method like\n",
      " |      ``pd.factorize(values)``. The results are identical for methods like\n",
      " |      :meth:`Series.factorize`.\n",
      " |      \n",
      " |      >>> labels, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'])\n",
      " |      >>> labels\n",
      " |      array([0, 0, 1, 2, 0])\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |      \n",
      " |      With ``sort=True``, the `uniques` will be sorted, and `labels` will be\n",
      " |      shuffled so that the relationship is the maintained.\n",
      " |      \n",
      " |      >>> labels, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'], sort=True)\n",
      " |      >>> labels\n",
      " |      array([1, 1, 0, 2, 1])\n",
      " |      >>> uniques\n",
      " |      array(['a', 'b', 'c'], dtype=object)\n",
      " |      \n",
      " |      Missing values are indicated in `labels` with `na_sentinel`\n",
      " |      (``-1`` by default). Note that missing values are never\n",
      " |      included in `uniques`.\n",
      " |      \n",
      " |      >>> labels, uniques = pd.factorize(['b', None, 'a', 'c', 'b'])\n",
      " |      >>> labels\n",
      " |      array([ 0, -1,  1,  2,  0])\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |      \n",
      " |      Thus far, we've only factorized lists (which are internally coerced to\n",
      " |      NumPy arrays). When factorizing pandas objects, the type of `uniques`\n",
      " |      will differ. For Categoricals, a `Categorical` is returned.\n",
      " |      \n",
      " |      >>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])\n",
      " |      >>> labels, uniques = pd.factorize(cat)\n",
      " |      >>> labels\n",
      " |      array([0, 0, 1])\n",
      " |      >>> uniques\n",
      " |      [a, c]\n",
      " |      Categories (3, object): [a, b, c]\n",
      " |      \n",
      " |      Notice that ``'b'`` is in ``uniques.categories``, desipite not being\n",
      " |      present in ``cat.values``.\n",
      " |      \n",
      " |      For all other pandas objects, an Index of the appropriate type is\n",
      " |      returned.\n",
      " |      \n",
      " |      >>> cat = pd.Series(['a', 'a', 'c'])\n",
      " |      >>> labels, uniques = pd.factorize(cat)\n",
      " |      >>> labels\n",
      " |      array([0, 0, 1])\n",
      " |      >>> uniques\n",
      " |      Index(['a', 'c'], dtype='object')\n",
      " |  \n",
      " |  item(self)\n",
      " |      return the first element of the underlying data as a python\n",
      " |      scalar\n",
      " |  \n",
      " |  nunique(self, dropna=True)\n",
      " |      Return number of unique elements in the object.\n",
      " |      \n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include NaN in the count.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique : int\n",
      " |  \n",
      " |  tolist(self)\n",
      " |      Return a list of the values.\n",
      " |      \n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.tolist\n",
      " |  \n",
      " |  transpose(self, *args, **kwargs)\n",
      " |      return the transpose, which is by definition self\n",
      " |  \n",
      " |  value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
      " |      Returns object containing counts of unique values.\n",
      " |      \n",
      " |      The resulting object will be in descending order so that the\n",
      " |      first element is the most frequently-occurring element.\n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      normalize : boolean, default False\n",
      " |          If True then the object returned will contain the relative\n",
      " |          frequencies of the unique values.\n",
      " |      sort : boolean, default True\n",
      " |          Sort by values\n",
      " |      ascending : boolean, default False\n",
      " |          Sort in ascending order\n",
      " |      bins : integer, optional\n",
      " |          Rather than count values, group them into half-open bins,\n",
      " |          a convenience for pd.cut, only works with numeric data\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include counts of NaN.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      counts : Series\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  base\n",
      " |      return the base object if the memory of the underlying data is\n",
      " |      shared\n",
      " |  \n",
      " |  data\n",
      " |      return the data pointer of the underlying data\n",
      " |  \n",
      " |  empty\n",
      " |  \n",
      " |  flags\n",
      " |      return the ndarray.flags for the underlying data\n",
      " |  \n",
      " |  hasnans\n",
      " |      return if I have any nans; enables various perf speedups\n",
      " |  \n",
      " |  is_monotonic\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic : boolean\n",
      " |  \n",
      " |  is_monotonic_decreasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_decreasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic_decreasing : boolean\n",
      " |  \n",
      " |  is_monotonic_increasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic : boolean\n",
      " |  \n",
      " |  is_unique\n",
      " |      Return boolean if values in the object are unique\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_unique : boolean\n",
      " |  \n",
      " |  itemsize\n",
      " |      return the size of the dtype of the item of the underlying data\n",
      " |  \n",
      " |  nbytes\n",
      " |      return the number of bytes in the underlying data\n",
      " |  \n",
      " |  ndim\n",
      " |      return the number of dimensions of the underlying data,\n",
      " |      by definition 1\n",
      " |  \n",
      " |  shape\n",
      " |      return a tuple of the shape of the underlying data\n",
      " |  \n",
      " |  size\n",
      " |      return the number of elements in the underlying data\n",
      " |  \n",
      " |  strides\n",
      " |      return the strides of the underlying data\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __deepcopy__(self, memo=None)\n",
      " |  \n",
      " |  __delitem__(self, key)\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self, other, method=None, **kwargs)\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : optional, a passed method name ; possibly to take different\n",
      " |          types of propagation actions based on this\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __pos__(self)\n",
      " |  \n",
      " |  __round__(self, decimals=0)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self)\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |      \n",
      " |      This function only applies to elements that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |      \n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |      \n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |      \n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : calculate the absolute value element-wise.\n",
      " |  \n",
      " |  add_prefix(self, prefix)\n",
      " |      Prefix labels with string `prefix`.\n",
      " |      \n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4],  'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  add_suffix(self, suffix)\n",
      " |      Suffix labels with string `suffix`.\n",
      " |      \n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4],  'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  as_blocks(self, copy=True)\n",
      " |      Convert the frame to a dict of dtype -> Constructor Types that each has\n",
      " |      a homogeneous dtype.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in\n",
      " |            as_matrix)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : a dict of dtype -> Constructor Types\n",
      " |  \n",
      " |  as_matrix(self, columns=None)\n",
      " |      Convert the frame to its Numpy-array representation.\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |          Use :meth:`DataFrame.values` instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns: list, optional, default:None\n",
      " |          If None, return all columns, otherwise, returns specified columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : ndarray\n",
      " |          If the caller is heterogeneous and contains booleans or objects,\n",
      " |          the result will be of dtype=object. See Notes.\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Return is NOT a Numpy-matrix, rather, a Numpy-array.\n",
      " |      \n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      " |      int32. By numpy.find_common_type convention, mixing int64 and uint64\n",
      " |      will result in a flot64 dtype.\n",
      " |      \n",
      " |      This method is provided for backwards compatibility. Generally,\n",
      " |      it is recommended to use '.values'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.values\n",
      " |  \n",
      " |  asfreq(self, freq, method=None, how=None, normalize=False, fill_value=None)\n",
      " |      Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Optionally provide filling method to pad/backfill missing values.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency. ``resample`` is more appropriate if an operation, such as\n",
      " |      summarization, is necessary to represent the data at the new frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset object, or string\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only, see PeriodIndex.asfreq\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight\n",
      " |      fill_value: scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s':series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      The last row without any NaN is taken (or the last row without\n",
      " |      NaN considering only the subset of columns in the case of a DataFrame)\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0 For DataFrame\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array of dates\n",
      " |      subset : string or list of strings, default None\n",
      " |         if not None use these columns for NaN propagation\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted\n",
      " |      Raises if this is not the case\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      where is scalar\n",
      " |      \n",
      " |        - value or NaN if input is Series\n",
      " |        - Series if input is DataFrame\n",
      " |      \n",
      " |      where is Index: same shape object as input\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof\n",
      " |  \n",
      " |  astype(self, dtype, copy=True, errors='raise', **kwargs)\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type, or dict of column name -> data type\n",
      " |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      " |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      " |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      " |          or more of the DataFrame's columns to column-specific types.\n",
      " |      copy : bool, default True.\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'.\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      raise_on_error : raise on invalid input\n",
      " |          .. deprecated:: 0.20.0\n",
      " |             Use ``errors`` instead\n",
      " |      kwargs : keyword arguments to pass on to the constructor\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Convert to categorical type:\n",
      " |      \n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [1, 2]\n",
      " |      \n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |      \n",
      " |      >>> ser.astype('category', ordered=True, categories=[2, 1])\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |      \n",
      " |      Note that using ``copy=False`` and changing data on a new\n",
      " |      pandas object may propagate changes:\n",
      " |      \n",
      " |      >>> s1 = pd.Series([1,2])\n",
      " |      >>> s2 = s1.astype('int64', copy=False)\n",
      " |      >>> s2[0] = 10\n",
      " |      >>> s1  # note that s1[0] has changed too\n",
      " |      0    10\n",
      " |      1     2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |  \n",
      " |  at_time(self, time, asof=False)\n",
      " |      Select values at particular time of day (e.g. 9:30AM).\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_at_time : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12H')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day\n",
      " |  \n",
      " |  between_time(self, start_time, end_time, include_start=True, include_end=True)\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or string\n",
      " |      end_time : datetime.time or string\n",
      " |      include_start : boolean, default True\n",
      " |      include_end : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_between_time : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      \n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |      \n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day\n",
      " |  \n",
      " |  bfill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='bfill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element PandasObject.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False.  Raise a\n",
      " |      ValueError if the PandasObject does not have exactly 1 element, or that\n",
      " |      element is not boolean\n",
      " |  \n",
      " |  clip(self, lower=None, upper=None, axis=None, inplace=False, *args, **kwargs)\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array_like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it.\n",
      " |      upper : float or array_like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it.\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip_lower : Clip values below specified threshold(s).\n",
      " |      clip_upper : Clip values above specified threshold(s).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |      \n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |      \n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |      \n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |  \n",
      " |  clip_lower(self, threshold, axis=None, inplace=False)\n",
      " |      Return copy of the input with values below a threshold truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : numeric or array-like\n",
      " |          Minimum value allowed. All values below threshold will be set to\n",
      " |          this value.\n",
      " |      \n",
      " |          * float : every value is compared to `threshold`.\n",
      " |          * array-like : The shape of `threshold` should match the object\n",
      " |            it's compared to. When `self` is a Series, `threshold` should be\n",
      " |            the length. When `self` is a DataFrame, `threshold` should 2-D\n",
      " |            and the same shape as `self` for ``axis=None``, or 1-D and the\n",
      " |            same length as the axis being compared.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Align `self` with `threshold` along the given axis.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.clip : Return copy of input with values below and above\n",
      " |          thresholds truncated.\n",
      " |      Series.clip_upper : Return copy of input with values above\n",
      " |          threshold truncated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Series single threshold clipping:\n",
      " |      \n",
      " |      >>> s = pd.Series([5, 6, 7, 8, 9])\n",
      " |      >>> s.clip_lower(8)\n",
      " |      0    8\n",
      " |      1    8\n",
      " |      2    8\n",
      " |      3    8\n",
      " |      4    9\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Series clipping element-wise using an array of thresholds. `threshold`\n",
      " |      should be the same length as the Series.\n",
      " |      \n",
      " |      >>> elemwise_thresholds = [4, 8, 7, 2, 5]\n",
      " |      >>> s.clip_lower(elemwise_thresholds)\n",
      " |      0    5\n",
      " |      1    8\n",
      " |      2    7\n",
      " |      3    8\n",
      " |      4    9\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      DataFrames can be compared to a scalar.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 3, 5], \"B\": [2, 4, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      >>> df.clip_lower(3)\n",
      " |         A  B\n",
      " |      0  3  3\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      Or to an array of values. By default, `threshold` should be the same\n",
      " |      shape as the DataFrame.\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([[3, 4], [2, 2], [6, 2]]))\n",
      " |         A  B\n",
      " |      0  3  4\n",
      " |      1  3  4\n",
      " |      2  6  6\n",
      " |      \n",
      " |      Control how `threshold` is broadcast with `axis`. In this case\n",
      " |      `threshold` should be the same length as the axis specified by\n",
      " |      `axis`.\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([3, 3, 5]), axis='index')\n",
      " |         A  B\n",
      " |      0  3  3\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([4, 5]), axis='columns')\n",
      " |         A  B\n",
      " |      0  4  5\n",
      " |      1  4  5\n",
      " |      2  5  6\n",
      " |  \n",
      " |  clip_upper(self, threshold, axis=None, inplace=False)\n",
      " |      Return copy of input with values above given value(s) truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : float or array_like\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with threshold along the given axis.\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |  \n",
      " |  consolidate(self, inplace=False)\n",
      " |      Compute NDFrame with \"consolidated\" internals (data of each dtype\n",
      " |      grouped together in a single ndarray).\n",
      " |      \n",
      " |      .. deprecated:: 0.20.0\n",
      " |          Consolidate will be an internal implementation only.\n",
      " |  \n",
      " |  convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)\n",
      " |      Attempt to infer better dtype for object columns.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      convert_dates : boolean, default True\n",
      " |          If True, convert to date where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      convert_numeric : boolean, default False\n",
      " |          If True, attempt to coerce to numbers (including strings), with\n",
      " |          unconvertible values becoming NaN.\n",
      " |      convert_timedeltas : boolean, default True\n",
      " |          If True, convert to timedelta where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      copy : boolean, default True\n",
      " |          If True, return a copy even if no copy is necessary (e.g. no\n",
      " |          conversion was done). Note: This is meant for internal use, and\n",
      " |          should not be confused with inplace.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Return a fixed frequency timedelta index,\n",
      " |          with day as the default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same as input object\n",
      " |  \n",
      " |  describe(self, percentiles=None, include=None, exclude=None)\n",
      " |      Generates descriptive statistics that summarize the central tendency,\n",
      " |      dispersion and shape of a dataset's distribution, excluding\n",
      " |      ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      summary:  Series/DataFrame of summary statistics\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                       3\n",
      " |      unique                      2\n",
      " |      top       2010-01-01 00:00:00\n",
      " |      freq                        2\n",
      " |      first     2000-01-01 00:00:00\n",
      " |      last      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({ 'object': ['a', 'b', 'c'],\n",
      " |      ...                     'numeric': [1, 2, 3],\n",
      " |      ...                     'categorical': pd.Categorical(['d','e','f'])\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')\n",
      " |              categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      c\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.object])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         c\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              f\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      c\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.object])\n",
      " |              categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count\n",
      " |      DataFrame.max\n",
      " |      DataFrame.min\n",
      " |      DataFrame.mean\n",
      " |      DataFrame.std\n",
      " |      DataFrame.select_dtypes\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Determines if two NDFrame objects contain the same elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |  \n",
      " |  ffill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  filter(self, items=None, like=None, regex=None, axis=None)\n",
      " |      Subset rows or columns of dataframe according to labels in\n",
      " |      the specified index.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          List of info axis to restrict to (must not all be present)\n",
      " |      like : string\n",
      " |          Keep info axis where \"arg in col == True\"\n",
      " |      regex : string (regular expression)\n",
      " |          Keep info axis with re.search(regex, col) == True\n",
      " |      axis : int or string axis name\n",
      " |          The axis to filter on.  By default this is the info axis,\n",
      " |          'index' for Series, 'columns' for DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |      one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |      one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.loc\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |  \n",
      " |  first(self, offset)\n",
      " |      Convenience method for subsetting initial periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the first 3 days:\n",
      " |      \n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      \n",
      " |      Notice the data for 3 first calender days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      between_time : Select values between particular times of the day\n",
      " |  \n",
      " |  first_valid_index(self)\n",
      " |      Return index for first non-NA/null value.\n",
      " |      \n",
      " |      Notes\n",
      " |      --------\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty NDFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      --------\n",
      " |      scalar : type of index\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (DataFrame column, Panel slice,\n",
      " |      etc.). Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : type of items contained in object\n",
      " |  \n",
      " |  get_dtype_counts(self)\n",
      " |      Return counts of unique dtypes in this object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dtype : Series\n",
      " |          Series with the count of columns with each dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dtypes : Return the dtypes in this object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = [['a', 1, 1.0], ['b', 2, 2.0], ['c', 3, 3.0]]\n",
      " |      >>> df = pd.DataFrame(a, columns=['str', 'int', 'float'])\n",
      " |      >>> df\n",
      " |        str  int  float\n",
      " |      0   a    1    1.0\n",
      " |      1   b    2    2.0\n",
      " |      2   c    3    3.0\n",
      " |      \n",
      " |      >>> df.get_dtype_counts()\n",
      " |      float64    1\n",
      " |      int64      1\n",
      " |      object     1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  get_ftype_counts(self)\n",
      " |      Return counts of unique ftypes in this object.\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |      \n",
      " |      This is useful for SparseDataFrame or for DataFrames containing\n",
      " |      sparse arrays.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dtype : Series\n",
      " |          Series with the count of columns with each type and\n",
      " |          sparsity (dense/sparse)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ftypes : Return ftypes (indication of sparse/dense and dtype) in\n",
      " |          this object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = [['a', 1, 1.0], ['b', 2, 2.0], ['c', 3, 3.0]]\n",
      " |      >>> df = pd.DataFrame(a, columns=['str', 'int', 'float'])\n",
      " |      >>> df\n",
      " |        str  int  float\n",
      " |      0   a    1    1.0\n",
      " |      1   b    2    2.0\n",
      " |      2   c    3    3.0\n",
      " |      \n",
      " |      >>> df.get_ftype_counts()\n",
      " |      float64:dense    1\n",
      " |      int64:dense      1\n",
      " |      object:dense     1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)\n",
      " |      Group series using mapper (dict or key function, apply given function\n",
      " |      to group, return result as series) or by a series of columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, or list of labels\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      " |          values are used as-is determine the groups. A label or list of\n",
      " |          labels may be passed to group by the columns in ``self``. Notice\n",
      " |          that a tuple is interpreted a (single) key.\n",
      " |      axis : int, default 0\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels\n",
      " |      as_index : boolean, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output\n",
      " |      sort : boolean, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group.  groupby preserves the order of rows within each group.\n",
      " |      group_keys : boolean, default True\n",
      " |          When calling apply, add group keys to index to identify pieces\n",
      " |      squeeze : boolean, default False\n",
      " |          reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type\n",
      " |      observed : boolean, default False\n",
      " |          This only applies if any of the groupers are Categoricals\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      GroupBy object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      DataFrame results\n",
      " |      \n",
      " |      >>> data.groupby(func, axis=0).mean()\n",
      " |      >>> data.groupby(['col1', 'col2'])['col3'].mean()\n",
      " |      \n",
      " |      DataFrame with hierarchical index\n",
      " |      \n",
      " |      >>> data.groupby(['col1', 'col2']).mean()\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/groupby.html>`_ for more.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Return the first `n` rows.\n",
      " |      \n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      obj_head : type of caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.tail: Returns the last `n` rows.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal':['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the first 5 lines\n",
      " |      \n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      \n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |  \n",
      " |  infer_objects(self)\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |      \n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |      \n",
      " |      .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Convert argument to numeric typeR\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same type as input object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |  \n",
      " |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', limit_area=None, downcast=None, **kwargs)\n",
      " |      Interpolate values according to different methods.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrames/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'linear', 'time', 'index', 'values', 'nearest', 'zero',\n",
      " |                'slinear', 'quadratic', 'cubic', 'barycentric', 'krogh',\n",
      " |                'polynomial', 'spline', 'piecewise_polynomial',\n",
      " |                'from_derivatives', 'pchip', 'akima'}\n",
      " |      \n",
      " |          * 'linear': ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |            default\n",
      " |          * 'time': interpolation works on daily and higher resolution\n",
      " |            data to interpolate given length of interval\n",
      " |          * 'index', 'values': use the actual numerical values of the index\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'barycentric', 'polynomial' is passed to\n",
      " |            ``scipy.interpolate.interp1d``. Both 'polynomial' and 'spline'\n",
      " |            require that you also specify an `order` (int),\n",
      " |            e.g. df.interpolate(method='polynomial', order=4).\n",
      " |            These use the actual numerical values of the index.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |            are all wrappers around the scipy interpolation methods of\n",
      " |            similar names. These use the actual numerical values of the\n",
      " |            index. For more information on their behavior, see the\n",
      " |            `scipy documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      " |            and `tutorial documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__\n",
      " |          * 'from_derivatives' refers to BPoly.from_derivatives which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |      \n",
      " |             Added support for the 'akima' method\n",
      " |             Added interpolate method 'from_derivatives' which replaces\n",
      " |             'piecewise_polynomial' in scipy 0.18; backwards-compatible with\n",
      " |             scipy < 0.18\n",
      " |      \n",
      " |      axis : {0, 1}, default 0\n",
      " |          * 0: fill column-by-column\n",
      " |          * 1: fill row-by-row\n",
      " |      limit : int, default None.\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than 0.\n",
      " |      limit_direction : {'forward', 'backward', 'both'}, default 'forward'\n",
      " |      limit_area : {'inside', 'outside'}, default None\n",
      " |          * None: (default) no fill restriction\n",
      " |          * 'inside' Only fill NaNs surrounded by valid values (interpolate).\n",
      " |          * 'outside' Only fill NaNs outside valid values (extrapolate).\n",
      " |      \n",
      " |          If limit is specified, consecutive NaNs will be filled in this\n",
      " |          direction.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      inplace : bool, default False\n",
      " |          Update the NDFrame in place if possible.\n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      kwargs : keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame of same shape interpolated at the NaNs\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, replace, fillna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Filling in NaNs\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s.interpolate()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  last(self, offset)\n",
      " |      Convenience method for subsetting final periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the last 3 days:\n",
      " |      \n",
      " |      >>> ts.last('3D')\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Notice the data for 3 last calender days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      between_time : Select values between particular times of the day\n",
      " |  \n",
      " |  last_valid_index(self)\n",
      " |      Return index for last non-NA/null value.\n",
      " |      \n",
      " |      Notes\n",
      " |      --------\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty NDFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      --------\n",
      " |      scalar : type of index\n",
      " |  \n",
      " |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where `cond` is False and otherwise are from\n",
      " |      `other`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10.0\n",
      " |      1    10.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where`\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
      " |      Percentage change between the current and a prior element.\n",
      " |      \n",
      " |      Computes the percentage change from the immediately previous row by\n",
      " |      default. This is useful in comparing the percentage of change in a time\n",
      " |      series of elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes.\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(fill_method='ffill')\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |      \n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |      \n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |      \n",
      " |      >>> df.pct_change(axis='columns')\n",
      " |            2016      2015      2014\n",
      " |      GOOG   NaN -0.151997 -0.086016\n",
      " |      APPL   NaN  0.337604  0.012002\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply func(self, \\*args, \\*\\*kwargs)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          function to apply to the NDFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the NDFrame.\n",
      " |      args : iterable, optional\n",
      " |          positional arguments passed into ``func``.\n",
      " |      kwargs : mapping, optional\n",
      " |          a dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      " |      \n",
      " |      >>> f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(f, arg2=b, arg3=c)\n",
      " |      ... )\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.apply\n",
      " |      pandas.DataFrame.applymap\n",
      " |      pandas.Series.map\n",
      " |  \n",
      " |  pop(self, item)\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : str\n",
      " |          Column label to be popped\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      popped : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=('name', 'class', 'max_speed'))\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      >>> df.pop('class')\n",
      " |      0      bird\n",
      " |      1      bird\n",
      " |      2    mammal\n",
      " |      3    mammal\n",
      " |      Name: class, dtype: object\n",
      " |      \n",
      " |      >>> df\n",
      " |           name  max_speed\n",
      " |      0  falcon      389.0\n",
      " |      1  parrot       24.0\n",
      " |      2    lion       80.5\n",
      " |      3  monkey        NaN\n",
      " |  \n",
      " |  rank(self, axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)\n",
      " |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      " |      assigned a rank that is the average of the ranks of those values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          index to direct ranking\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. Valid only for DataFrame or\n",
      " |          Panel objects\n",
      " |      na_option : {'keep', 'top', 'bottom'}\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      pct : boolean, default False\n",
      " |          Computes percentage rank of data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ranks : same type as caller\n",
      " |  \n",
      " |  reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)\n",
      " |      Return an object with matching indices to myself.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object\n",
      " |      method : string or None\n",
      " |      copy : boolean, default True\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between labels of the other object and this\n",
      " |          object for inexact matches. Can be list-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Like calling s.reindex(index=other.index, columns=other.columns,\n",
      " |                             method=...)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : same as input\n",
      " |  \n",
      " |  rename_axis(self, mapper, axis=0, copy=True, inplace=False)\n",
      " |      Alter the name of the index or columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set as the axis name attribute.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis.\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : boolean, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Series, DataFrame, or None\n",
      " |          The same type as the caller or None if `inplace` is True.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Prior to version 0.21.0, ``rename_axis`` could also be used to change\n",
      " |      the axis *labels* by passing a mapping or scalar. This behavior is\n",
      " |      deprecated and will be removed in a future version. Use ``rename``\n",
      " |      instead.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.rename : Alter Series index labels or name\n",
      " |      pandas.DataFrame.rename : Alter DataFrame index labels or name\n",
      " |      pandas.Index.rename : Set new names on index\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.rename_axis(\"foo\")\n",
      " |      foo\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename_axis(\"foo\")\n",
      " |           A  B\n",
      " |      foo\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |      \n",
      " |      >>> df.rename_axis(\"bar\", axis=\"columns\")\n",
      " |      bar  A  B\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |  \n",
      " |  resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0, on=None, level=None)\n",
      " |      Convenience method for frequency conversion and resampling of time\n",
      " |      series.  Object must have a datetime-like index (DatetimeIndex,\n",
      " |      PeriodIndex, or TimedeltaIndex), or pass datetime-like values\n",
      " |      to the on or level keyword.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : string\n",
      " |          the offset string or object representing target conversion\n",
      " |      axis : int, optional, default 0\n",
      " |      closed : {'right', 'left'}\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}\n",
      " |          For PeriodIndex only, controls whether to use the start or end of\n",
      " |          `rule`\n",
      " |      kind: {'timestamp', 'period'}, optional\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          ``DateTimeIndex`` or 'period' to convert it to a ``PeriodIndex``.\n",
      " |          By default the input representation is retained.\n",
      " |      loffset : timedelta\n",
      " |          Adjust the resampled time labels\n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      level : string or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling.  Level must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Resampler object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#resampling>`_\n",
      " |      for more.\n",
      " |      \n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5] #select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``pad`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').pad()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(array_like):\n",
      " |      ...     return np.sum(array_like)+5\n",
      " |      \n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      " |      used to control whether to use the start or end of `rule`.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      " |                                                      freq='A',\n",
      " |                                                      periods=2))\n",
      " |      >>> s\n",
      " |      2012    1\n",
      " |      2013    2\n",
      " |      Freq: A-DEC, dtype: int64\n",
      " |      \n",
      " |      Resample by month using 'start' `convention`. Values are assigned to\n",
      " |      the first month of the period.\n",
      " |      \n",
      " |      >>> s.resample('M', convention='start').asfreq().head()\n",
      " |      2012-01    1.0\n",
      " |      2012-02    NaN\n",
      " |      2012-03    NaN\n",
      " |      2012-04    NaN\n",
      " |      2012-05    NaN\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      Resample by month using 'end' `convention`. Values are assigned to\n",
      " |      the last month of the period.\n",
      " |      \n",
      " |      >>> s.resample('M', convention='end').asfreq()\n",
      " |      2012-12    1.0\n",
      " |      2013-01    NaN\n",
      " |      2013-02    NaN\n",
      " |      2013-03    NaN\n",
      " |      2013-04    NaN\n",
      " |      2013-05    NaN\n",
      " |      2013-06    NaN\n",
      " |      2013-07    NaN\n",
      " |      2013-08    NaN\n",
      " |      2013-09    NaN\n",
      " |      2013-10    NaN\n",
      " |      2013-11    NaN\n",
      " |      2013-12    2.0\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword ``on`` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(data=9*[range(4)], columns=['a', 'b', 'c', 'd'])\n",
      " |      >>> df['time'] = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> df.resample('3T', on='time').sum()\n",
      " |                           a  b  c  d\n",
      " |      time\n",
      " |      2000-01-01 00:00:00  0  3  6  9\n",
      " |      2000-01-01 00:03:00  0  3  6  9\n",
      " |      2000-01-01 00:06:00  0  3  6  9\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword ``level`` can be used to\n",
      " |      specify on level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> time = pd.date_range('1/1/2000', periods=5, freq='T')\n",
      " |      >>> df2 = pd.DataFrame(data=10*[range(4)],\n",
      " |                             columns=['a', 'b', 'c', 'd'],\n",
      " |                             index=pd.MultiIndex.from_product([time, [1, 2]])\n",
      " |                             )\n",
      " |      >>> df2.resample('3T', level=0).sum()\n",
      " |                           a  b   c   d\n",
      " |      2000-01-01 00:00:00  0  6  12  18\n",
      " |      2000-01-01 00:03:00  0  4   8  12\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      groupby : Group by mapping, function, label, or list of labels.\n",
      " |  \n",
      " |  sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : boolean, optional\n",
      " |          Sample with or without replacement. Default = False.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          inf and -inf values not allowed.\n",
      " |      random_state : int or numpy.random.RandomState, optional\n",
      " |          Seed for the random number generator (if int), or numpy RandomState\n",
      " |          object.\n",
      " |      axis : int or string, optional\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type (0 for Series and DataFrames, 1 for Panels).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A new object of same type as caller.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Generate an example ``Series`` and ``DataFrame``:\n",
      " |      \n",
      " |      >>> s = pd.Series(np.random.randn(50))\n",
      " |      >>> s.head()\n",
      " |      0   -0.038497\n",
      " |      1    1.820773\n",
      " |      2   -0.972766\n",
      " |      3   -1.598270\n",
      " |      4   -1.095526\n",
      " |      dtype: float64\n",
      " |      >>> df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n",
      " |      >>> df.head()\n",
      " |                A         B         C         D\n",
      " |      0  0.016443 -2.318952 -0.566372 -1.028078\n",
      " |      1 -1.051921  0.438836  0.658280 -0.175797\n",
      " |      2 -1.243569 -0.364626 -0.215065  0.057736\n",
      " |      3  1.768216  0.404512 -0.385604 -1.457834\n",
      " |      4  1.072446 -1.137172  0.314194 -0.046661\n",
      " |      \n",
      " |      Next extract a random sample from both of these objects...\n",
      " |      \n",
      " |      3 random elements from the ``Series``:\n",
      " |      \n",
      " |      >>> s.sample(n=3)\n",
      " |      27   -0.994689\n",
      " |      55   -1.049016\n",
      " |      67   -0.224565\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      And a random 10% of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.1, replace=True)\n",
      " |                 A         B         C         D\n",
      " |      35  1.981780  0.142106  1.817165 -0.290805\n",
      " |      49 -1.336199 -0.448634 -0.789640  0.217116\n",
      " |      40  0.823173 -0.078816  1.009536  1.015108\n",
      " |      15  1.421154 -0.055301 -1.922594 -0.019696\n",
      " |      6  -0.148339  0.832938  1.787600 -1.383767\n",
      " |      \n",
      " |      You can use `random state` for reproducibility:\n",
      " |      \n",
      " |      >>> df.sample(random_state=1)\n",
      " |      A         B         C         D\n",
      " |      37 -2.027662  0.103611  0.237496 -0.165867\n",
      " |      43 -0.259323 -0.583426  1.516140 -0.479118\n",
      " |      12 -1.686325 -0.579510  0.985195 -0.460286\n",
      " |      8   1.167946  0.429082  1.215742 -1.636041\n",
      " |      9   1.197475 -0.864188  1.554031 -1.505264\n",
      " |  \n",
      " |  select(self, crit, axis=0)\n",
      " |      Return data corresponding to axis labels matching criteria\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use df.loc[df.index.map(crit)] to select via labels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      crit : function\n",
      " |          To be called on each index (label). Should return True or False\n",
      " |      axis : int\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      selection : type of caller\n",
      " |  \n",
      " |  set_axis(self, labels, axis=0, inplace=None)\n",
      " |      Assign desired index to given axis.\n",
      " |      \n",
      " |      Indexes for column or row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |      \n",
      " |      .. versionchanged:: 0.21.0\n",
      " |      \n",
      " |         The signature is now `labels` and `axis`, consistent with\n",
      " |         the rest of pandas API. Previously, the `axis` and `labels`\n",
      " |         arguments were respectively the first and second positional\n",
      " |         arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows, and 1\n",
      " |          identifies the columns.\n",
      " |      \n",
      " |      inplace : boolean, default None\n",
      " |          Whether to return a new %(klass)s instance.\n",
      " |      \n",
      " |          .. warning::\n",
      " |      \n",
      " |             ``inplace=None`` currently falls back to to True, but in a\n",
      " |             future version, will default to False. Use inplace=True\n",
      " |             explicitly rather than relying on the default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : %(klass)s or None\n",
      " |          An object of same type as caller if inplace=False, None otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.rename_axis : Alter the name of the index or columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.set_axis(['a', 'b', 'c'], axis=0, inplace=False)\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The original object is not modified.\n",
      " |      \n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      \n",
      " |      Change the row labels.\n",
      " |      \n",
      " |      >>> df.set_axis(['a', 'b', 'c'], axis='index', inplace=False)\n",
      " |         A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      \n",
      " |      Change the column labels.\n",
      " |      \n",
      " |      >>> df.set_axis(['I', 'II'], axis='columns', inplace=False)\n",
      " |         I  II\n",
      " |      0  1   4\n",
      " |      1  2   5\n",
      " |      2  3   6\n",
      " |      \n",
      " |      Now, update the labels inplace.\n",
      " |      \n",
      " |      >>> df.set_axis(['i', 'ii'], axis='columns', inplace=True)\n",
      " |      >>> df\n",
      " |         i  ii\n",
      " |      0  1   4\n",
      " |      1  2   5\n",
      " |      2  3   6\n",
      " |  \n",
      " |  slice_shift(self, periods=1, axis=0)\n",
      " |      Equivalent to `shift` without copying data. The shifted data will\n",
      " |      not include the dropped periods and the shifted axis will be smaller\n",
      " |      than the original.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |  \n",
      " |  squeeze(self, axis=None)\n",
      " |      Squeeze length 1 dimensions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : None, integer or string axis name, optional\n",
      " |          The axis to squeeze if 1-sized.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar if 1-sized, else original object\n",
      " |  \n",
      " |  swapaxes(self, axis1, axis2, copy=True)\n",
      " |      Interchange axes and swap values axes appropriately\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Return the last `n` rows.\n",
      " |      \n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.head : The first `n` rows of the caller object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal':['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the last 5 lines\n",
      " |      \n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |      \n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |  \n",
      " |  take(self, indices, axis=0, convert=None, is_copy=True, **kwargs)\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      convert : bool, default True\n",
      " |          Whether to convert negative indices into positive ones.\n",
      " |          For example, ``-1`` would map to the ``len(axis) - 1``.\n",
      " |          The conversions are similar to the behavior of indexing a\n",
      " |          regular Python list.\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |             In the future, negative indices will always be converted.\n",
      " |      \n",
      " |      is_copy : bool, default True\n",
      " |          Whether to return a copy of the original object or not.\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : type of caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                    columns=['name', 'class', 'max_speed'],\n",
      " |      ...                    index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  to_clipboard(self, excel=True, sep=None, **kwargs)\n",
      " |      Copy object to the system clipboard.\n",
      " |      \n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          - True, use the provided separator, writing in a csv format for\n",
      " |            allowing easy pasting into excel.\n",
      " |          - False, write a string representation of the object to the\n",
      " |            clipboard.\n",
      " |      \n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |      \n",
      " |        - Linux : `xclip`, or `xsel` (with `gtk` or `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - OS X : none\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |      >>> df.to_clipboard(sep=',')\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |      \n",
      " |      We can omit the the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',', index=False)\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |  \n",
      " |  to_dense(self)\n",
      " |      Return dense representation of NDFrame (as opposed to sparse)\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key, **kwargs)\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |      \n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |      \n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |      \n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      format : {'fixed', 'table'}, default 'fixed'\n",
      " |          Possible values:\n",
      " |      \n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      data_columns :  list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See :ref:`io.hdf5-query-data-columns`.\n",
      " |          Applicable only to format='table'.\n",
      " |      complevel : {0-9}, optional\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      fletcher32 : bool, default False\n",
      " |          If applying compression use the fletcher32 checksum.\n",
      " |      dropna : bool, default False\n",
      " |          If true, ALL nan rows will not be written to store.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')\n",
      " |      \n",
      " |      We can add another object to the same file:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_hdf('data.h5', key='s')\n",
      " |      \n",
      " |      Reading from HDF file:\n",
      " |      \n",
      " |      >>> pd.read_hdf('data.h5', 'df')\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Deleting file with data:\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove('data.h5')\n",
      " |  \n",
      " |  to_json(self, path_or_buf=None, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression=None, index=True)\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : string or file handle, optional\n",
      " |          File path or object. If not specified, the result is returned as\n",
      " |          a string.\n",
      " |      orient : string\n",
      " |          Indication of expected JSON string format.\n",
      " |      \n",
      " |          * Series\n",
      " |      \n",
      " |            - default is 'index'\n",
      " |            - allowed values are: {'split','records','index'}\n",
      " |      \n",
      " |          * DataFrame\n",
      " |      \n",
      " |            - default is 'columns'\n",
      " |            - allowed values are:\n",
      " |              {'split','records','index','columns','values'}\n",
      " |      \n",
      " |          * The format of the JSON string\n",
      " |      \n",
      " |            - 'split' : dict like {'index' -> [index],\n",
      " |              'columns' -> [columns], 'data' -> [values]}\n",
      " |            - 'records' : list like\n",
      " |              [{column -> value}, ... , {column -> value}]\n",
      " |            - 'index' : dict like {index -> {column -> value}}\n",
      " |            - 'columns' : dict like {column -> {index -> value}}\n",
      " |            - 'values' : just the values array\n",
      " |            - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |              describing the data, and the data component is\n",
      " |              like ``orient='records'``.\n",
      " |      \n",
      " |              .. versionchanged:: 0.20.0\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values.\n",
      " |      force_ascii : boolean, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : string, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : boolean, default False\n",
      " |          If 'orient' is 'records' write out line delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not list\n",
      " |          like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      compression : {None, 'gzip', 'bz2', 'zip', 'xz'}\n",
      " |          A string representing the compression to use in the output file,\n",
      " |          only used when the first argument is a filename.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      index : boolean, default True\n",
      " |          Whether to include the index values in the JSON string. Not\n",
      " |          including the index (``index=False``) is only supported when\n",
      " |          orient is 'split' or 'table'.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.read_json\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                   index=['row 1', 'row 2'],\n",
      " |      ...                   columns=['col 1', 'col 2'])\n",
      " |      >>> df.to_json(orient='split')\n",
      " |      '{\"columns\":[\"col 1\",\"col 2\"],\n",
      " |        \"index\":[\"row 1\",\"row 2\"],\n",
      " |        \"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> df.to_json(orient='records')\n",
      " |      '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='index')\n",
      " |      '{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='columns')\n",
      " |      '{\"col 1\":{\"row 1\":\"a\",\"row 2\":\"c\"},\"col 2\":{\"row 1\":\"b\",\"row 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='values')\n",
      " |      '[[\"a\",\"b\"],[\"c\",\"d\"]]'\n",
      " |      \n",
      " |      Encoding with Table Schema\n",
      " |      \n",
      " |      >>> df.to_json(orient='table')\n",
      " |      '{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 1\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 2\", \"type\": \"string\"}],\n",
      " |                   \"primaryKey\": \"index\",\n",
      " |                   \"pandas_version\": \"0.20.0\"},\n",
      " |        \"data\": [{\"index\": \"row 1\", \"col 1\": \"a\", \"col 2\": \"b\"},\n",
      " |                 {\"index\": \"row 2\", \"col 1\": \"c\", \"col 2\": \"d\"}]}'\n",
      " |  \n",
      " |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None)\n",
      " |      Render an object to a tabular environment table. You can splice\n",
      " |      this into a LaTeX document. Requires \\\\usepackage{booktabs}.\n",
      " |      \n",
      " |      .. versionchanged:: 0.20.2\n",
      " |         Added to Series\n",
      " |      \n",
      " |      `to_latex`-specific options:\n",
      " |      \n",
      " |      bold_rows : boolean, default False\n",
      " |          Make the row labels bold in the output\n",
      " |      column_format : str, default None\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g 'rcl' for 3\n",
      " |          columns\n",
      " |      longtable : boolean, default will be read from the pandas config module\n",
      " |          Default: False.\n",
      " |          Use a longtable environment instead of tabular. Requires adding\n",
      " |          a \\\\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : boolean, default will be read from the pandas config module\n",
      " |          Default: True.\n",
      " |          When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      encoding : str, default None\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      " |      decimal : string, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      multicolumn : boolean, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multicolumn_format : str, default 'l'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multirow : boolean, default False\n",
      " |          Use \\multirow to enhance MultiIndex rows.\n",
      " |          Requires adding a \\\\usepackage{multirow} to your LaTeX preamble.\n",
      " |          Will print centered labels (instead of top-aligned)\n",
      " |          across the contained rows, separating groups via clines.\n",
      " |          The default will be read from the pandas config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |  \n",
      " |  to_msgpack(self, path_or_buf=None, encoding='utf-8', **kwargs)\n",
      " |      msgpack (serialize) object to input file path\n",
      " |      \n",
      " |      THIS IS AN EXPERIMENTAL LIBRARY and the storage format\n",
      " |      may not be stable until a future release.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string File path, buffer-like, or None\n",
      " |          if None, return generated string\n",
      " |      append : boolean whether to append to an existing msgpack\n",
      " |          (default is False)\n",
      " |      compress : type of compressor (zlib or blosc), default to None (no\n",
      " |          compression)\n",
      " |  \n",
      " |  to_pickle(self, path, compression='infer', protocol=4)\n",
      " |      Pickle (serialize) object to file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str\n",
      " |          File path where the pickled object will be stored.\n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None},         default 'infer'\n",
      " |          A string representing the compression to use in the output file. By\n",
      " |          default, infers from the file extension in specified path.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values for this parameter depend on the version of Python. For\n",
      " |          Python 2.x, possible values are 0, 1, 2. For Python>=3.0, 3 is a\n",
      " |          valid value. For Python >= 3.4, 4 is a valid value. A negative\n",
      " |          value for the protocol parameter is equivalent to setting its value\n",
      " |          to HIGHEST_PROTOCOL.\n",
      " |      \n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html\n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})\n",
      " |      >>> original_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")\n",
      " |      \n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")\n",
      " |      >>> unpickled_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove(\"./dummy.pkl\")\n",
      " |  \n",
      " |  to_sql(self, name, con, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : string\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.Engine or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects.\n",
      " |      schema : string, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |      \n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |      \n",
      " |      index : boolean, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table.\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Rows will be written in batches of this size at a time. By default,\n",
      " |          all rows will be written at once.\n",
      " |      dtype : dict, optional\n",
      " |          Specifying the datatype for columns. The keys should be the column\n",
      " |          names and the values should be the SQLAlchemy types or strings for\n",
      " |          the sqlite3 legacy mode.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.read_sql : read a DataFrame from a table\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] http://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create an in-memory SQLite database.\n",
      " |      \n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |      \n",
      " |      Create a table from scratch with 3 rows.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |      \n",
      " |      >>> df.to_sql('users', con=engine)\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      >>> df1.to_sql('users', con=engine, if_exists='append')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5')]\n",
      " |      \n",
      " |      Overwrite the table with just ``df1``.\n",
      " |      \n",
      " |      >>> df1.to_sql('users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 4'), (1, 'User 5')]\n",
      " |      \n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |      \n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql('integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      \n",
      " |      >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a DataArray for a Series\n",
      " |      a Dataset for a DataFrame\n",
      " |      a DataArray for higher dims\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)})\n",
      " |      >>> df\n",
      " |         A    B    C\n",
      " |      0  1  foo  4.0\n",
      " |      1  1  bar  5.0\n",
      " |      2  2  foo  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (index: 3)\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2\n",
      " |      Data variables:\n",
      " |          A        (index) int64 1 1 2\n",
      " |          B        (index) object 'foo' 'bar' 'foo'\n",
      " |          C        (index) float64 4.0 5.0 6.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)}\n",
      " |                           ).set_index(['B','A'])\n",
      " |      >>> df\n",
      " |               C\n",
      " |      B   A\n",
      " |      foo 1  4.0\n",
      " |      bar 1  5.0\n",
      " |      foo 2  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (A: 2, B: 2)\n",
      " |      Coordinates:\n",
      " |        * B        (B) object 'bar' 'foo'\n",
      " |        * A        (A) int64 1 2\n",
      " |      Data variables:\n",
      " |          C        (B, A) float64 5.0 nan 4.0 6.0\n",
      " |      \n",
      " |      >>> p = pd.Panel(np.arange(24).reshape(4,3,2),\n",
      " |                       items=list('ABCD'),\n",
      " |                       major_axis=pd.date_range('20130101', periods=3),\n",
      " |                       minor_axis=['first', 'second'])\n",
      " |      >>> p\n",
      " |      <class 'pandas.core.panel.Panel'>\n",
      " |      Dimensions: 4 (items) x 3 (major_axis) x 2 (minor_axis)\n",
      " |      Items axis: A to D\n",
      " |      Major_axis axis: 2013-01-01 00:00:00 to 2013-01-03 00:00:00\n",
      " |      Minor_axis axis: first to second\n",
      " |      \n",
      " |      >>> p.to_xarray()\n",
      " |      <xarray.DataArray (items: 4, major_axis: 3, minor_axis: 2)>\n",
      " |      array([[[ 0,  1],\n",
      " |              [ 2,  3],\n",
      " |              [ 4,  5]],\n",
      " |             [[ 6,  7],\n",
      " |              [ 8,  9],\n",
      " |              [10, 11]],\n",
      " |             [[12, 13],\n",
      " |              [14, 15],\n",
      " |              [16, 17]],\n",
      " |             [[18, 19],\n",
      " |              [20, 21],\n",
      " |              [22, 23]]])\n",
      " |      Coordinates:\n",
      " |        * items       (items) object 'A' 'B' 'C' 'D'\n",
      " |        * major_axis  (major_axis) datetime64[ns] 2013-01-01 2013-01-02 2013-01-03  # noqa\n",
      " |        * minor_axis  (minor_axis) object 'first' 'second'\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <http://xarray.pydata.org/en/stable/>`__\n",
      " |  \n",
      " |  truncate(self, before=None, after=None, axis=None, copy=True)\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |      \n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, string, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, string, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |      copy : boolean, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                    index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |      \n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      \n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |      \n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |      \n",
      " |      For Series, only rows can be truncated.\n",
      " |      \n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |      \n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |      \n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |      \n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |      \n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |      \n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |  \n",
      " |  tshift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |  \n",
      " |  tz_convert(self, tz, axis=0, level=None, copy=True)\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous='raise')\n",
      " |      Localize tz-naive TimeSeries to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |  \n",
      " |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where `cond` is True and otherwise are from\n",
      " |      `other`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10.0\n",
      " |      1    10.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask`\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, drop_level=True)\n",
      " |      Returns a cross-section (row(s) or column(s)) from the\n",
      " |      Series/DataFrame. Defaults to cross-section on the rows (axis=0).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |          Some label contained in the index, or partially in a MultiIndex\n",
      " |      axis : int, default 0\n",
      " |          Axis to retrieve cross-section on\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : boolean, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      a  4  5  2\n",
      " |      b  4  0  9\n",
      " |      c  9  7  3\n",
      " |      >>> df.xs('a')\n",
      " |      A    4\n",
      " |      B    5\n",
      " |      C    2\n",
      " |      Name: a\n",
      " |      >>> df.xs('C', axis=1)\n",
      " |      a    2\n",
      " |      b    9\n",
      " |      c    3\n",
      " |      Name: C\n",
      " |      \n",
      " |      >>> df\n",
      " |                          A  B  C  D\n",
      " |      first second third\n",
      " |      bar   one    1      4  1  8  9\n",
      " |            two    1      7  5  5  0\n",
      " |      baz   one    1      6  6  8  0\n",
      " |            three  2      5  3  5  3\n",
      " |      >>> df.xs(('baz', 'three'))\n",
      " |             A  B  C  D\n",
      " |      third\n",
      " |      2      5  3  5  3\n",
      " |      >>> df.xs('one', level=1)\n",
      " |                   A  B  C  D\n",
      " |      first third\n",
      " |      bar   1      4  1  8  9\n",
      " |      baz   1      6  6  8  0\n",
      " |      >>> df.xs(('baz', 2), level=[0, 'third'])\n",
      " |              A  B  C  D\n",
      " |      second\n",
      " |      three   5  3  5  3\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xs : Series or DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      xs is only for getting, not setting values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on any level or\n",
      " |      levels.  It is a superset of xs functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |      \n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s)\n",
      " |      Series.at : Access a single value using a label\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a Series\n",
      " |      \n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          When label does not exist in DataFrame\n",
      " |  \n",
      " |  blocks\n",
      " |      Internal property, property synonym for as_blocks()\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |  \n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |      \n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s)\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a series\n",
      " |      \n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`\n",
      " |  \n",
      " |  is_copy\n",
      " |  \n",
      " |  ix\n",
      " |      A primarily label-location based indexer, with integer position\n",
      " |      fallback.\n",
      " |      \n",
      " |      Warning: Starting in 0.20.0, the .ix indexer is deprecated, in\n",
      " |      favor of the more strict .iloc and .loc indexers.\n",
      " |      \n",
      " |      ``.ix[]`` supports mixed integer and label based access. It is\n",
      " |      primarily label based, but will fall back to integer positional\n",
      " |      access unless the corresponding axis is of integer type.\n",
      " |      \n",
      " |      ``.ix`` is the most general indexer and will support any of the\n",
      " |      inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n",
      " |      point label schemes. ``.ix`` is exceptionally useful when dealing\n",
      " |      with mixed positional and label based hierarchical indexes.\n",
      " |      \n",
      " |      However, when an axis is integer based, ONLY label based access\n",
      " |      and not positional access is supported. Thus, in such cases, it's\n",
      " |      usually better to be explicit and use ``.iloc`` or ``.loc``.\n",
      " |      \n",
      " |      See more at :ref:`Advanced Indexing <advanced>`.\n",
      " |  \n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |      \n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |      \n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s)\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |          Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...      columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |      \n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |      \n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label for row and column\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |      \n",
      " |      Boolean list with the same length as the row axis\n",
      " |      \n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |      \n",
      " |      Callable that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      **Setting values**\n",
      " |      \n",
      " |      Set value for all items matching the list of labels\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire row\n",
      " |      \n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire column\n",
      " |      \n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |      \n",
      " |      Set value for rows matching callable condition\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |      \n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |      \n",
      " |      Another example using integers for the index\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      **Getting values with a MultiIndex**\n",
      " |      \n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |      \n",
      " |      >>> tuples = [\n",
      " |      ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...         [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |      \n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |      \n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |      \n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |      \n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |      \n",
      " |      Single tuple for the index with a single label for the column\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice from index tuple to single label\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Slice from index tuple to index tuple\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError:\n",
      " |          when any items are not found\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help (SweepSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**  Continuting the previous exercise, use `run_multiple_simulations` to run simulations with a range of values for `p1` and\n",
    "\n",
    "```\n",
    "p2 = 0.3\n",
    "num_steps = 60\n",
    "num_runs = 20\n",
    "```\n",
    "\n",
    "Store the results in a `SweepSeries`, then plot the average number of unhappy customers as a function of `p1`.  Label the axes.\n",
    "\n",
    "What value of `p1` minimizes the average number of unhappy customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
